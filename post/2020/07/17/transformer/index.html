<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Transformer | Renovamen (Xiaohan Zou)</title>
    <meta name="generator" content="VuePress 1.7.1">
    <link rel="icon" href="/img/logo.svg">
    <meta name="description" content="Renovamen's blog, powered by VuePress, themed by Gungnir.">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    
    <link rel="preload" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/css/0.styles.9717c134.css" as="style"><link rel="preload" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/app.293b3460.js" as="script"><link rel="preload" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/9.1660df00.js" as="script"><link rel="preload" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/1.bee6a65f.js" as="script"><link rel="preload" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/2.559efb66.js" as="script"><link rel="preload" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/10.2b27df40.js" as="script"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/11.66f1a07b.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/12.381d064d.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/13.fd3a0a2a.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/14.85f7547e.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/15.c87e918c.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/16.e479303e.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/17.9e8f20ee.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/18.2db9b037.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/19.b003f2d9.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/20.18bbaf9e.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/21.b2ec6cd9.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/22.20c800f5.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/23.69b596b7.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/24.f088ef87.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/25.12407065.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/26.80a6d210.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/27.8a7662c4.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/28.4b679b5c.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/29.ebc169ad.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/30.504bf36b.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/31.c4809391.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/32.e03a42c3.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/33.9cd56518.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/4.d079bdaf.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/5.02164026.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/6.e4fae646.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/7.fc766c56.js"><link rel="prefetch" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/8.94dcaf7a.js">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/css/0.styles.9717c134.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container post-container no-sidebar" data-v-2964d8cc><header class="navbar invert" data-v-2964d8cc><a href="/" class="home-link router-link-active"><span class="site-name">$ cd /home/</span></a> <div class="links"><nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link faa-parent animated-hover"><svg aria-hidden="true" width="14.4" height="14.4" viewBox="0 0 512 512" focusable="false" class="faa-wrench v-icon" style="font-size:0.9em;"><g><path d="M489.2 287.9c2.6 0 4.6 2 4.5 4.6v219.5h-182.9v-96c0-72.6-109.7-72.6-109.7 0v96h-182.9v-219.5c0-2.6 2-4.6 4.6-4.6h27.4c2.6 0 4.6 2 4.6 4.6v32h36.6v-178.3c0-2.6 2-4.6 4.6-4.6h27.4c2.6 0 4.6 2 4.6 4.6v32h36.3v-32c0-2.6 2-4.6 4.6-4.6h27.4c2.6 0 4.6 2 4.6 4.6v32h36.6v-32c0-6 8-4.6 11.7-4.6v-111.7c-5.4-2.6-9.1-8.3-9.1-14.3 0-20.8 31.4-20.7 31.4 0 0 6-3.7 11.7-9.1 14.3v4.9c7.7-1.8 15.7-2.9 23.7-2.9 11.7 0 22.9 4.3 32.6 4.3 8.9 0 18.9-4.3 24-4.3 2.6 0 4.6 2 4.6 4.6v60c0 6.9-23.1 8-27.7 8-10.5 0-20.5-4.3-31.4-4.3-8.6 0-17.4 1.4-25.7 3.4v38c3.7 0 11.7-1.4 11.7 4.6v32h36.6v-32c0-2.6 2-4.6 4.6-4.6h27.4c2.6 0 4.6 2 4.6 4.6v32h36.6v-32c0-2.6 2-4.6 4.6-4.6h27.4c2.6 0 4.6 2 4.6 4.6v178.3h36.6v-32c0-2.6 2-4.6 4.6-4.6h27.4zM201.1 283.4v-64c0-2.6-2-4.6-4.6-4.6h-27.4c-2.6 0-4.6 2-4.6 4.6v64c0 2.6 2 4.6 4.6 4.6h27.4c2.6 0 4.6-2 4.6-4.6zM347.5 283.4v-64c0-2.6-2-4.6-4.6-4.6h-27.4c-2.6 0-4.6 2-4.6 4.6v64c0 2.6 2 4.6 4.6 4.6h27.4c2.6 0 4.6-2 4.6-4.6z"></path></g></svg>
  Home
</a></div><div class="nav-item"><a href="/about/" class="nav-link faa-parent animated-hover"><svg aria-hidden="true" width="14.4" height="14.4" viewBox="0 0 512 512" focusable="false" class="faa-wrench v-icon" style="font-size:0.9em;"><g><path d="M256 224c79.4 0 192 122.8 192 200.3 0 34.9-26.8 55.8-71.7 55.7-48.4 0-80.8-25.1-120.3-25.1-39.2 0-71.4 25.1-120.3 25.1-44.9 0-71.7-20.8-71.7-55.8 0-77.5 112.6-200.3 192-200.2zM108.7 211.4c10.4 34.7-4.8 68.4-33.9 75.3-29.1 7-61.2-15.5-71.5-50.1-10.4-34.6 4.8-68.4 33.9-75.3s61.2 15.5 71.5 50.1zM193.4 190.6c-30.9 8.1-65.6-20.5-77.4-63.9-11.8-43.4 3.6-85.2 34.6-93.3 30.9-8.1 65.6 20.5 77.4 63.8 11.8 43.4-3.6 85.2-34.6 93.4zM474.8 161.3c29.1 7 44.3 40.7 33.9 75.3-10.4 34.6-42.4 57.1-71.5 50.1s-44.3-40.7-33.9-75.3c10.4-34.7 42.4-57.1 71.5-50.1zM318.6 190.6c-30.9-8.1-46.4-49.9-34.6-93.4 11.8-43.4 46.5-72 77.4-63.8 30.9 8.2 46.4 49.9 34.6 93.3-11.8 43.4-46.5 72-77.4 63.9z"></path></g></svg>
  About
</a></div><div class="nav-item"><a href="/tags/" class="nav-link faa-parent animated-hover"><svg aria-hidden="true" width="14.4" height="14.4" viewBox="0 0 512 512" focusable="false" class="faa-wrench v-icon" style="font-size:0.9em;"><g><path d="M0 252.1v-204.1c0-26.5 21.5-48 48-48h204.1c13.2 0 25.3 5.4 34 14.1l211.8 211.8c18.7 18.7 18.7 49.1 0 67.9l-204.1 204.1c-18.7 18.7-49.1 18.7-67.9 0l-211.8-211.8c-8.7-8.7-14.1-20.7-14.1-34zM112 64c-26.5 0-48 21.5-48 48s21.5 48 48 48 48-21.5 48-48-21.5-48-48-48z"></path></g></svg>
  Tags
</a></div><div class="nav-item"><a href="/links/" class="nav-link faa-parent animated-hover"><svg aria-hidden="true" width="14.4" height="14.4" viewBox="0 0 512 512" focusable="false" class="faa-wrench v-icon" style="font-size:0.9em;"><g><path d="M305.4 462.6c7.4 7.3 6.2 20.1-3 25-77.7 41.8-176.7 29.9-242.3-35.7-65.6-65.6-77.5-164.5-35.7-242.3 4.9-9.1 17.7-10.3 25-3l116.8 116.8 27.4-27.4c-0.7-2.6-1.6-5-1.6-7.8 0-17.7 14.3-32 32-32 17.7 0 32 14.3 32 32 0 17.7-14.3 32-32 32-2.8 0-5.2-0.9-7.8-1.6l-27.4 27.4zM512 303.1c0 0.3 0 0.6 0 0.9 0 8.9-7.2 16-16 16.1h-32.1c-8.5 0-15.4-6.7-15.9-15-7.5-129.5-111.5-234.5-241-241.6-8.3-0.4-15-7.4-15-15.8 0 0 0-0.1 0-0.1v-31.6c0-8.9 7.2-16 16.1-16 0.3 0 0.6 0 0.9 0 163.2 8.6 294.4 139.8 303 303.1zM416 302.8c0 0.4 0 0.7 0 1.1 0 8.9-7.2 16.2-16.1 16.2h-32.3c-8.3-0.1-15.2-6.5-15.8-14.7-6.9-77-68.1-138.9-145-145.3-8.3-0.6-14.8-7.5-14.8-15.9v-32.1 0c0-8.9 7.2-16.1 16.2-16.1 0.4 0 0.8 0 1.1 0 110.1 8.5 198.2 96.6 206.7 206.8z"></path></g></svg>
  Links
</a></div> <div class="nav-item"><a class="nav-link faa-parent animated-hover" style="cursor: pointer;"><svg aria-hidden="true" width="14.4" height="14.4" viewBox="0 0 512 512" focusable="false" class="faa-wrench v-icon" style="font-size:0.9em;"><g><path d="M505 442.7c9.3 9.4 9.3 24.6-0.1 34l-28.3 28.3c-9.3 9.4-24.5 9.4-33.9 0l-99.7-99.7c-4.5-4.5-7-10.6-7-17v-16.3c-35.3 27.6-79.7 44-128 44-114.9 0-208-93.1-208-208s93.1-208 208-208 208 93.1 208 208c0 48.3-16.4 92.7-44 128h16.3c6.4 0 12.5 2.5 17 7zM208 336c70.8 0 128-57.3 128-128 0-70.8-57.3-128-128-128-70.8 0-128 57.3-128 128 0 70.8 57.3 128 128 128z"></path></g></svg>
      Search
    </a></div></nav></div></header> <div class="sidebar-mask" data-v-2964d8cc></div> <aside class="sidebar" data-v-2964d8cc><div class="personal-info-wrapper" data-v-2964d8cc><div class="mobile-hero-avatar" data-v-2964d8cc><img src="/img/avatar.jpeg" alt="hero" data-v-2964d8cc></div> <p class="mobile-heading" data-v-2964d8cc>Renovamen</p> <div class="sns-wrapper" data-v-2964d8cc><a href="https://github.com/Renovamen" target="_blank" rel="noopener noreferrer"><svg aria-hidden="true" width="0" height="0" viewBox="0 0 0 0" focusable="false" class="icon-stack v-icon"><g><!----> <svg aria-hidden="true" width="16.5" height="17.6" viewBox="0 0 480 512" focusable="false" class="icon-sns v-icon v-inverse" style="font-size:1.1em;"><g><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1-25.8 0-36.7-34.2-36.7-55.1 0-20.9 10.9-55.1 36.7-55.1 25.8 0 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zM415.7 328.7c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-0.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zM333.1 273.6c25.8 0 36.7 34.2 36.7 55.1 0 20.9-10.9 55.1-36.7 55.1-25.8 0-36.7-34.2-36.7-55.1 0-20.9 10.9-55.1 36.7-55.1z"></path></g></svg></g></svg></a><a href="https://www.linkedin.com/in/xiaohan-zou-55bba0160" target="_blank" rel="noopener noreferrer"><svg aria-hidden="true" width="0" height="0" viewBox="0 0 0 0" focusable="false" class="icon-stack v-icon"><g><!----> <svg aria-hidden="true" width="15.400000000000002" height="17.6" viewBox="0 0 448 512" focusable="false" class="icon-sns v-icon v-inverse" style="font-size:1.1em;"><g><path d="M100.3 448h-92.9v-299.1h92.9v299.1zM53.8 108.1c-29.7 0-53.8-24.6-53.8-54.3 0-29.7 24.1-53.8 53.8-53.8s53.8 24.1 53.8 53.8c0 29.7-24.1 54.3-53.8 54.3zM447.9 448h-92.7v-145.6c0-34.7-0.7-79.2-48.3-79.2-48.3 0-55.7 37.7-55.7 76.7v148.1h-92.7v-299.1h89v40.8h1.3c12.4-23.5 42.7-48.3 87.9-48.3 94 0 111.3 61.9 111.3 142.3v164.3h-0.1z"></path></g></svg></g></svg></a><a href="https://www.facebook.com/renovamen.zou" target="_blank" rel="noopener noreferrer"><svg aria-hidden="true" width="0" height="0" viewBox="0 0 0 0" focusable="false" class="icon-stack v-icon"><g><!----> <svg aria-hidden="true" width="11" height="17.6" viewBox="0 0 320 512" focusable="false" class="icon-sns v-icon v-inverse" style="font-size:1.1em;"><g><path d="M279.1 288h-74.6v224h-100.2v-224h-81.4v-92.7h81.4v-70.6c0-80.3 47.9-124.7 121.1-124.7 35.1 0 71.8 6.3 71.7 6.3v78.9h-40.4c-39.8 0-52.2 24.7-52.2 50v60.1h88.9z"></path></g></svg></g></svg></a><a href="https://www.twitter.com/renovamen_zxh" target="_blank" rel="noopener noreferrer"><svg aria-hidden="true" width="0" height="0" viewBox="0 0 0 0" focusable="false" class="icon-stack v-icon"><g><!----> <svg aria-hidden="true" width="17.6" height="17.6" viewBox="0 0 512 512" focusable="false" class="icon-sns v-icon v-inverse" style="font-size:1.1em;"><g><path d="M459.4 151.7c0.3 4.5 0.3 9.1 0.3 13.7 0 138.7-105.6 298.6-298.6 298.5-59.5 0-114.7-17.2-161.1-47.1 8.4 1 16.6 1.3 25.3 1.3 49.1 0 94.2-16.6 130.3-44.8-46.1-1-84.8-31.2-98.1-72.8 6.5 1 13 1.6 19.8 1.6 9.4 0 18.8-1.3 27.6-3.5-48.1-9.7-84.1-52-84.1-103v-1.3c14 7.8 30.2 12.7 47.4 13.3-28.3-18.8-46.8-51-46.8-87.4 0-19.5 5.2-37.4 14.3-53 51.7 63.7 129.3 105.3 216.4 109.9-1.6-7.8-2.6-15.9-2.6-24.1 0-57.8 46.8-104.9 104.9-104.9 30.2 0 57.5 12.7 76.7 33.1 23.7-4.5 46.5-13.3 66.6-25.3-7.8 24.4-24.4 44.8-46.1 57.8 21.1-2.3 41.6-8.1 60.4-16.2-14.3 20.8-32.2 39.3-52.6 54.2z"></path></g></svg></g></svg></a><a href="https://www.zhihu.com/people/chao-neng-gui-su" target="_blank" rel="noopener noreferrer"><svg aria-hidden="true" width="0" height="0" viewBox="0 0 0 0" focusable="false" class="icon-stack v-icon"><g><!----> <svg aria-hidden="true" width="17.6" height="17.6" viewBox="0 0 1200 1200" focusable="false" class="icon-sns v-icon v-inverse" style="font-size:1.1em;"><g><path d="M617.2 898.2L532.8 951.9 426.3 784.4C404.3 854.5 367.6 917.6 319.3 975.6 299.2 999.8 278.3 1021.5 254.3 1044.4 246.5 1051.7 215.5 1080.2 210.3 1085.4L139.7 1014.7C146.6 1007.7 179 977.9 185.4 971.9 206.9 951.5 225.2 932.4 242.5 911.5 305.8 835.7 344 751 349.4 650H150V550H350V350H306.6C272.1 413.3 228.7 461.1 175.7 492.8L124.3 407.2C194.1 365.3 245.6 277 276.2 139.2L373.8 160.8C366.8 192.5 358.6 222.2 349.4 250H575V350H450V550H575V650H459.3L617.2 898.2zM809.1 894.7L864.9 850H950V350H750V850H786.8L809.1 894.7zM650 250H1050V950H900L775 1050 725 950H650V250z"></path></g></svg></g></svg></a><a href="mailto:renovamenzxh@gmail.com" target="_blank" rel="noopener noreferrer"><svg aria-hidden="true" width="0" height="0" viewBox="0 0 0 0" focusable="false" class="icon-stack v-icon"><g><!----> <svg aria-hidden="true" width="17.6" height="17.6" viewBox="0 0 512 512" focusable="false" class="icon-sns v-icon v-inverse" style="font-size:1.1em;"><g><path d="M502.3 190.8c3.9-3.1 9.7-0.2 9.7 4.7v204.5c0 26.5-21.5 48-48 48h-416c-26.5 0-48-21.5-48-48v-204.4c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7 0.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c-23.2 0.4-56.6-29.2-73.4-41.4-132.7-96.3-142.8-104.8-173.4-128.7-5.8-4.6-9.2-11.5-9.2-18.9v-19c0-26.5 21.5-48 48-48h416c26.5 0 48 21.5 48 48v19c0 7.4-3.4 14.4-9.2 18.9-30.6 24-40.7 32.4-173.4 128.7-16.8 12.2-50.2 41.8-73.4 41.4z"></path></g></svg></g></svg></a> <a href="/rss.xml" target="_blank" rel="noopener noreferrer"><svg aria-hidden="true" width="0" height="0" viewBox="0 0 0 0" focusable="false" class="icon-stack v-icon"><g><!----> <svg aria-hidden="true" width="16.099999999999998" height="18.4" viewBox="0 0 448 512" focusable="false" class="icon-sns v-icon v-inverse" style="font-size:1.15em;"><g><path d="M128.1 416c0 35.4-28.7 64-64.1 64s-64-28.7-64-64 28.7-64 64-64.1 64 28.7 64.1 64.1zM303.7 463.2c0.5 9.1-6.8 16.8-16 16.8h-48c-8.4 0-15.5-6.5-16-14.9-7.3-112.1-96.9-201.5-208.8-208.8-8.4-0.5-14.9-7.6-14.9-16v-48c0-9.1 7.7-16.5 16.8-16 154.8 8.4 278.6 132.4 286.9 286.9zM448 463.5c0.3 9-7 16.5-16 16.5h-48.1c-8.6 0-15.6-6.8-16-15.5-7.8-191.1-161.3-344.6-352.4-352.4-8.6-0.4-15.5-7.4-15.5-16v-48.1c0-9 7.5-16.3 16.5-16 235 8.4 423.1 197.7 431.5 431.5z"></path></g></svg></g></svg></a></div> <hr data-v-2964d8cc></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link faa-parent animated-hover"><svg aria-hidden="true" width="14.4" height="14.4" viewBox="0 0 512 512" focusable="false" class="faa-wrench v-icon" style="font-size:0.9em;"><g><path d="M489.2 287.9c2.6 0 4.6 2 4.5 4.6v219.5h-182.9v-96c0-72.6-109.7-72.6-109.7 0v96h-182.9v-219.5c0-2.6 2-4.6 4.6-4.6h27.4c2.6 0 4.6 2 4.6 4.6v32h36.6v-178.3c0-2.6 2-4.6 4.6-4.6h27.4c2.6 0 4.6 2 4.6 4.6v32h36.3v-32c0-2.6 2-4.6 4.6-4.6h27.4c2.6 0 4.6 2 4.6 4.6v32h36.6v-32c0-6 8-4.6 11.7-4.6v-111.7c-5.4-2.6-9.1-8.3-9.1-14.3 0-20.8 31.4-20.7 31.4 0 0 6-3.7 11.7-9.1 14.3v4.9c7.7-1.8 15.7-2.9 23.7-2.9 11.7 0 22.9 4.3 32.6 4.3 8.9 0 18.9-4.3 24-4.3 2.6 0 4.6 2 4.6 4.6v60c0 6.9-23.1 8-27.7 8-10.5 0-20.5-4.3-31.4-4.3-8.6 0-17.4 1.4-25.7 3.4v38c3.7 0 11.7-1.4 11.7 4.6v32h36.6v-32c0-2.6 2-4.6 4.6-4.6h27.4c2.6 0 4.6 2 4.6 4.6v32h36.6v-32c0-2.6 2-4.6 4.6-4.6h27.4c2.6 0 4.6 2 4.6 4.6v178.3h36.6v-32c0-2.6 2-4.6 4.6-4.6h27.4zM201.1 283.4v-64c0-2.6-2-4.6-4.6-4.6h-27.4c-2.6 0-4.6 2-4.6 4.6v64c0 2.6 2 4.6 4.6 4.6h27.4c2.6 0 4.6-2 4.6-4.6zM347.5 283.4v-64c0-2.6-2-4.6-4.6-4.6h-27.4c-2.6 0-4.6 2-4.6 4.6v64c0 2.6 2 4.6 4.6 4.6h27.4c2.6 0 4.6-2 4.6-4.6z"></path></g></svg>
  Home
</a></div><div class="nav-item"><a href="/about/" class="nav-link faa-parent animated-hover"><svg aria-hidden="true" width="14.4" height="14.4" viewBox="0 0 512 512" focusable="false" class="faa-wrench v-icon" style="font-size:0.9em;"><g><path d="M256 224c79.4 0 192 122.8 192 200.3 0 34.9-26.8 55.8-71.7 55.7-48.4 0-80.8-25.1-120.3-25.1-39.2 0-71.4 25.1-120.3 25.1-44.9 0-71.7-20.8-71.7-55.8 0-77.5 112.6-200.3 192-200.2zM108.7 211.4c10.4 34.7-4.8 68.4-33.9 75.3-29.1 7-61.2-15.5-71.5-50.1-10.4-34.6 4.8-68.4 33.9-75.3s61.2 15.5 71.5 50.1zM193.4 190.6c-30.9 8.1-65.6-20.5-77.4-63.9-11.8-43.4 3.6-85.2 34.6-93.3 30.9-8.1 65.6 20.5 77.4 63.8 11.8 43.4-3.6 85.2-34.6 93.4zM474.8 161.3c29.1 7 44.3 40.7 33.9 75.3-10.4 34.6-42.4 57.1-71.5 50.1s-44.3-40.7-33.9-75.3c10.4-34.7 42.4-57.1 71.5-50.1zM318.6 190.6c-30.9-8.1-46.4-49.9-34.6-93.4 11.8-43.4 46.5-72 77.4-63.8 30.9 8.2 46.4 49.9 34.6 93.3-11.8 43.4-46.5 72-77.4 63.9z"></path></g></svg>
  About
</a></div><div class="nav-item"><a href="/tags/" class="nav-link faa-parent animated-hover"><svg aria-hidden="true" width="14.4" height="14.4" viewBox="0 0 512 512" focusable="false" class="faa-wrench v-icon" style="font-size:0.9em;"><g><path d="M0 252.1v-204.1c0-26.5 21.5-48 48-48h204.1c13.2 0 25.3 5.4 34 14.1l211.8 211.8c18.7 18.7 18.7 49.1 0 67.9l-204.1 204.1c-18.7 18.7-49.1 18.7-67.9 0l-211.8-211.8c-8.7-8.7-14.1-20.7-14.1-34zM112 64c-26.5 0-48 21.5-48 48s21.5 48 48 48 48-21.5 48-48-21.5-48-48-48z"></path></g></svg>
  Tags
</a></div><div class="nav-item"><a href="/links/" class="nav-link faa-parent animated-hover"><svg aria-hidden="true" width="14.4" height="14.4" viewBox="0 0 512 512" focusable="false" class="faa-wrench v-icon" style="font-size:0.9em;"><g><path d="M305.4 462.6c7.4 7.3 6.2 20.1-3 25-77.7 41.8-176.7 29.9-242.3-35.7-65.6-65.6-77.5-164.5-35.7-242.3 4.9-9.1 17.7-10.3 25-3l116.8 116.8 27.4-27.4c-0.7-2.6-1.6-5-1.6-7.8 0-17.7 14.3-32 32-32 17.7 0 32 14.3 32 32 0 17.7-14.3 32-32 32-2.8 0-5.2-0.9-7.8-1.6l-27.4 27.4zM512 303.1c0 0.3 0 0.6 0 0.9 0 8.9-7.2 16-16 16.1h-32.1c-8.5 0-15.4-6.7-15.9-15-7.5-129.5-111.5-234.5-241-241.6-8.3-0.4-15-7.4-15-15.8 0 0 0-0.1 0-0.1v-31.6c0-8.9 7.2-16 16.1-16 0.3 0 0.6 0 0.9 0 163.2 8.6 294.4 139.8 303 303.1zM416 302.8c0 0.4 0 0.7 0 1.1 0 8.9-7.2 16.2-16.1 16.2h-32.3c-8.3-0.1-15.2-6.5-15.8-14.7-6.9-77-68.1-138.9-145-145.3-8.3-0.6-14.8-7.5-14.8-15.9v-32.1 0c0-8.9 7.2-16.1 16.2-16.1 0.4 0 0.8 0 1.1 0 110.1 8.5 198.2 96.6 206.7 206.8z"></path></g></svg>
  Links
</a></div> <div class="nav-item"><a class="nav-link faa-parent animated-hover" style="cursor: pointer;"><svg aria-hidden="true" width="14.4" height="14.4" viewBox="0 0 512 512" focusable="false" class="faa-wrench v-icon" style="font-size:0.9em;"><g><path d="M505 442.7c9.3 9.4 9.3 24.6-0.1 34l-28.3 28.3c-9.3 9.4-24.5 9.4-33.9 0l-99.7-99.7c-4.5-4.5-7-10.6-7-17v-16.3c-35.3 27.6-79.7 44-128 44-114.9 0-208-93.1-208-208s93.1-208 208-208 208 93.1 208 208c0 48.3-16.4 92.7-44 128h16.3c6.4 0 12.5 2.5 17 7zM208 336c70.8 0 128-57.3 128-128 0-70.8-57.3-128-128-128-70.8 0-128 57.3-128 128 0 70.8 57.3 128 128 128z"></path></g></svg>
      Search
    </a></div></nav> <!----> </aside> <div class="post-header" data-v-32f48eff> <div class="header-content" data-v-32f48eff><div class="tags" data-v-32f48eff><span class="tag" data-v-32f48eff>NLP</span></div> <h1 class="title" data-v-32f48eff>Transformer</h1> <h3 class="subtitle" data-v-32f48eff>试图理一理 Transformer</h3> <div class="icons" data-v-32f48eff><div class="icon" data-v-32f48eff><svg aria-hidden="true" width="12.6" height="14.4" viewBox="0 0 448 512" focusable="false" class="v-icon" style="font-size:0.9em;" data-v-32f48eff><g><path d="M313.6 304c74.2 0 134.4 60.2 134.4 134.4v25.6c0 26.5-21.5 48-48 48h-352c-26.5 0-48-21.5-48-48v-25.6c0-74.2 60.2-134.4 134.4-134.4 28.8 0 42.5 16 89.6 16s60.9-16 89.6-16zM400 464v-25.6c0-47.6-38.8-86.4-86.4-86.4-14.7 0-37.9 16-89.6 16-51.3 0-75-16-89.6-16-47.6 0-86.4 38.8-86.4 86.4v25.6h352zM224 288c-79.5 0-144-64.5-144-144s64.5-144 144-144 144 64.5 144 144-64.5 144-144 144zM224 48c-52.9 0-96 43.1-96 96s43.1 96 96 96 96-43.1 96-96-43.1-96-96-96z"></path></g></svg> <span data-v-32f48eff>Renovamen</span></div> <div class="icon" data-v-32f48eff><svg aria-hidden="true" width="12.6" height="14.4" viewBox="0 0 448 512" focusable="false" class="v-icon" style="font-size:0.9em;" data-v-32f48eff><g><path d="M400 64c26.5 0 48 21.5 48 48v352c0 26.5-21.5 48-48 48h-352c-26.5 0-48-21.5-48-48v-352c0-26.5 21.5-48 48-48h48v-52c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v52h128v-52c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v52h48zM394 464c3.3 0 6-2.7 6-6v-298h-352v298c0 3.3 2.7 6 6 6h340z"></path></g></svg> <span data-v-32f48eff>2020-07-17</span></div> <div class="icon" data-v-32f48eff><svg aria-hidden="true" width="14.4" height="14.4" viewBox="0 0 512 512" focusable="false" class="v-icon" style="font-size:0.9em;" data-v-32f48eff><g><path d="M256 8c137 0 248 111 248 248s-111 248-248 248-248-111-248-248 111-248 248-248zM256 456c110.5 0 200-89.5 200-200s-89.5-200-200-200-200 89.5-200 200 89.5 200 200 200zM317.8 351.6l-84.9-61.7c-3.1-2.3-4.9-5.9-4.9-9.7v-164.2c0-6.6 5.4-12 12-12h32c6.6 0 12 5.4 12 12v141.7l66.8 48.6c5.4 3.9 6.5 11.4 2.6 16.8l-18.8 25.9c-3.9 5.3-11.4 6.5-16.8 2.6z"></path></g></svg> <span data-v-32f48eff>10 min</span></div></div></div></div> <main class="page"><!----> <div class="theme-content content__default"><p><strong>Attention Is All You Need.</strong> <em>Ashish Vaswani, et al.</em> NIPS 2017. <a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py" target="_blank" rel="noopener noreferrer">[Code]</a></p> <p>考虑到 RNN 只能单向依次计算，所以存在以下问题：</p> <ul><li><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span> 时刻的计算依赖与 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">t-1</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.69841em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> 时刻的计算结果，限制了模型的并行能力</p></li> <li><p>RNN 的长期依赖问题</p></li></ul> <p>于是这篇论文扔掉了 encoder 和 decoder 中的 RNN 结构，完全用 attention 来搞 machine translation：</p> <ul><li><p>没有 RNN 结构，所以有更好的并行能力</p></li> <li><p>attention 机制对全局信息的处理更有效</p></li></ul> <p>Transformer 整体结构如下：</p> <img src="/img/in-post/2020-07-17/transformer.png" width="400px" alt="Transformer"> <h2 id="position-embedding"><a href="#position-embedding" class="header-anchor">#</a> Position Embedding</h2> <p>Transformer 扔掉了 RNN，对输入句子的所有单词都是同时处理的，所以失去了捕捉单词的排序和位置信息的能力。如果不解决词序的问题，那即使把一句话打乱，attention 出来的结果也是一样的，相当于这就只是一个词袋模型。为了解决这个问题，论文引入 position embedding 来对单词的位置信息进行编码。最终的输入词向量 = word embedding + position embedding：</p> <p><img src="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/img/positional-embedding.bbe028d1.png" alt="Positional Embedding"></p> <p class="desc">图片来源：<a href="http://jalammar.github.io/illustrated-transformer#representing-the-order-of-the-sequence-using-positional-encoding" target="_blank">The Illustrated Transformer</a></p> <p>有两种搞到 position embedding 的思路：</p> <ul><li><p>学习出一份 position embedding（<a href="http://proceedings.mlr.press/v70/gehring17a/gehring17a.pdf" target="_blank" rel="noopener noreferrer"><strong>Convolutional Sequence to Sequence Learning</strong></a>. <em>Jonas Gehring et al.</em> ICML 2017.）</p></li> <li><p>直接用不同频率的 sin 和 cos 函数算出来</p></li></ul> <p>经过实验，论文发现这俩方法效果差不多，所以选了第二种方法，因为它有以下好处：</p> <ul><li><p>不需要加额外的训练参数</p></li> <li><p>学习出来的 position embedding 会受到训练集中序列的长度的限制，但三角函数明显不受序列长度的限制，所以能够处理训练集中没见过的序列长度</p></li></ul> <p>具体的位置编码公式为：</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mi>E</mi><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo stretchy="false">)</mo><mo>=</mo><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><mrow><mn>1000</mn><msup><mn>0</mn><mfrac><mrow><mn>2</mn><mi>i</mi></mrow><msub><mi>d</mi><mtext>model</mtext></msub></mfrac></msup></mrow></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">PE(pos, 2i) = \sin(\frac{pos}{10000^{\frac{2i}{d_{\text{model}}}}})
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mord mathnormal">i</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.11949em;vertical-align:-1.01193em;"></span><span class="mop">sin</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.11em;"><span class="pstrut" style="height:3.12193em;"></span><span class="mord"><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.1219299999999999em;"><span style="top:-3.5233700000000003em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8550857142857142em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em;"><span class="pstrut" style="height:2.69444em;"></span><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34963999999999995em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5937428571428571em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.35193em;"><span class="pstrut" style="height:3.12193em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.79893em;"><span class="pstrut" style="height:3.12193em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.01193em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></span></p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mi>E</mi><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator="true">,</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo>=</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><mrow><mn>1000</mn><msup><mn>0</mn><mfrac><mrow><mn>2</mn><mi>i</mi></mrow><msub><mi>d</mi><mtext>model</mtext></msub></mfrac></msup></mrow></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">PE(pos, 2i+1) = \cos(\frac{pos}{10000^{\frac{2i}{d_{\text{model}}}}})
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.11949em;vertical-align:-1.01193em;"></span><span class="mop">cos</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.11em;"><span class="pstrut" style="height:3.12193em;"></span><span class="mord"><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.1219299999999999em;"><span style="top:-3.5233700000000003em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8550857142857142em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em;"><span class="pstrut" style="height:2.69444em;"></span><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.34963999999999995em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5937428571428571em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.35193em;"><span class="pstrut" style="height:3.12193em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.79893em;"><span class="pstrut" style="height:3.12193em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.01193em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></span></p> <p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mtext>model</mtext></msub></mrow><annotation encoding="application/x-tex">d_{\text{model}}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 为词嵌入维度（论文中为 512），pos 为该单词在序列中的位置，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>i</mi></mrow><annotation encoding="application/x-tex">2i</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord mathnormal">i</span></span></span></span> 为词向量的偶数维度（用第一个公式），<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">2i+1</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.74285em;vertical-align:-0.08333em;"></span><span class="mord">2</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> 指词向量的奇数维度（用第二个公式）。波的频率和偏移对于每个维度是不同的：</p> <p><img src="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/img/wave.5fd3e2a1.png" alt="wave"></p> <p class="desc">图片来源：<a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding" target="_blank">The Annotated Transformer</a></p> <p>因为三角函数还有以下特性：</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>α</mi><mo>+</mo><mi>β</mi><mo stretchy="false">)</mo><mo>=</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>α</mi><mo stretchy="false">)</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>β</mi><mo stretchy="false">)</mo><mo>−</mo><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>α</mi><mo stretchy="false">)</mo><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>β</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\cos(\alpha + \beta) = \cos(\alpha) \cos(\beta) - \sin(\alpha) \sin(\beta)
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">cos</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">cos</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">cos</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">sin</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">sin</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mclose">)</span></span></span></span></span></p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>α</mi><mo>+</mo><mi>β</mi><mo stretchy="false">)</mo><mo>=</mo><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>α</mi><mo stretchy="false">)</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>β</mi><mo stretchy="false">)</mo><mo>+</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>α</mi><mo stretchy="false">)</mo><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>β</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sin(\alpha + \beta) = \sin(\alpha) \cos(\beta) + \cos(\alpha) \sin(\beta)
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">sin</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">sin</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">cos</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">cos</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">sin</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mclose">)</span></span></span></span></span></p> <p>所以任意位置的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>E</mi><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo>+</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">PE(pos+k)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span></span></span></span> 都能通过 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>E</mi><mo stretchy="false">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">PE(pos)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mord mathnormal">o</span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span> 线性表达，这为模型捕捉单词之间的相对位置关系提供了非常大的便利。</p> <h2 id="encoder"><a href="#encoder" class="header-anchor">#</a> Encoder</h2> <p>论文中的 encoder 由 N = 6 个相同的 layer 堆叠而成：</p> <img src="/img/in-post/2020-07-17/encoder.png" width="180px" alt="encoder"> <p>每个 layer 由两个 sub-layer 组成，分别为 multi-head self-attention 和 fully connected feed-forward network。</p> <p>并且每个 sub-layer 都加了：</p> <ul><li><p>Residual Connection：解决多层神经网络训练困难的问题，通过将前一层的信息无差的传递到下一层，可以有效的仅关注差异部分</p></li> <li><p>Layer Normalisation：对层的激活值进行归一化，可以加速模型的训练过程，使其更快的收敛</p> <p><a href="https://arxiv.org/pdf/1607.06450.pdf" target="_blank" rel="noopener noreferrer"><strong>Layer Normalization</strong></a>. <em>Jimmy Lei Ba, et al.</em> arXiv 2016.</p></li></ul> <p>也就是输入会先进 LayerNorm，再进 sub-layer，然后加在原始输入上（虽然图上 LayerNorm 似乎在 sub-layer 后面，但<a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html#encoder" target="_blank" rel="noopener noreferrer">代码</a>里的确是先进 LayerNorm）。最后 6 个 layer 都跑完之后还要再单独 norm 一次（虽然图上没画但<a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html#encoder" target="_blank" rel="noopener noreferrer">代码</a>里写了）。</p> <h3 id="muti-head-self-attention"><a href="#muti-head-self-attention" class="header-anchor">#</a> Muti-Head Self-Attention</h3> <p>attention 可以表示为以下形式：</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>a</mi><mi>t</mi><mi>t</mi><mi mathvariant="normal">_</mi><mi>o</mi><mi>u</mi><mi>t</mi><mo>=</mo><mtext>Attention</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">att\_out = \text{Attention}(Q, K, V)
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.9250799999999999em;vertical-align:-0.31em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">t</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Attention</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span></span></span></span></span></p> <p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>（value）用来求加权和得到最终的上下文向量，而 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span></span></span></span>（query）和所有的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span>（key）会被用来计算注意力权重。如在传统的 seq2seq 结构中，它们分别由以下值经过线性变换得到：</p> <ul><li><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span></span></span></span>：decoder 的当前输入</p></li> <li><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>：encoder 的输出（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>h</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>h</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">h_1, h_2, \dots, h_n</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>）</p></li> <li><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span>：同 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></p></li></ul> <p>而这里是 self-attention，所以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo separator="true">,</mo><mi>V</mi><mo separator="true">,</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">Q, V, K</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> 由同一个值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span></span></span></span> 经过线性变换得到，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span></span></span></span> 在第一个 layer 为输入的词向量序列，在之后的 layer 则为上一个 layer 的输出。</p> <p>而 multi-head attention 就是通过 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">h=8</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span></span></span></span> 个不同的线性变换得到不同的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo separator="true">,</mo><mi>V</mi><mo separator="true">,</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">Q, V, K</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span>，最后将这 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">h</span></span></span></span> 个 attention 结果拼接起来：</p> <p><img src="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/img/multi-head-self-attention.6ff112a6.png" alt="multi-head sekf-attention"></p> <p class="desc">图片来源：<a href="http://jalammar.github.io/illustrated-transformer#the-beast-with-many-heads" target="_blank">The Illustrated Transformer</a></p> <p>这里的 attention 计算公式为（scaled dot-product）：</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Attention</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mo stretchy="false">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">\text{Attention}(Q, K, V) = \text{softmax}(\frac{QK^T}{\sqrt{d_k}}) V
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Attention</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.448331em;vertical-align:-0.93em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183309999999999em;"><span style="top:-2.25278em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85722em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.81722em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.18278000000000005em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span></p> <p>注意：这里跟 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span> 是<strong>矩阵相乘</strong>，不是 element-wise 相乘。</p> <p><img src="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/img/attention.8d27f0e6.png" alt="attention"></p> <p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub><mo>=</mo><msub><mi>d</mi><mtext>model</mtext></msub><mi mathvariant="normal">/</mi><mi>h</mi><mo>=</mo><mn>512</mn><mi mathvariant="normal">/</mi><mn>8</mn><mo>=</mo><mn>64</mn></mrow><annotation encoding="application/x-tex">d_k = d_{\text{model}} / h = 512 / 8 = 64</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">5</span><span class="mord">1</span><span class="mord">2</span><span class="mord">/</span><span class="mord">8</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span><span class="mord">4</span></span></span></span>。除以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{d_k}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1.04em;vertical-align:-0.18278000000000005em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85722em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.81722em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.18278000000000005em;"><span></span></span></span></span></span></span></span></span> 是因为，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">d_k</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 越大 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">QK^T</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1.035771em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span> 就会越大，可能就会将 softmax 函数推入梯度极小的区域，所以要用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{d_k}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1.04em;vertical-align:-0.18278000000000005em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85722em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.81722em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.18278000000000005em;"><span></span></span></span></span></span></span></span></span> 对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">QK^T</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1.035771em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span> 进行缩放。</p> <p>图中的 mask 只会在 <a href="#masked-multi-head-self-attention">decoder</a> 中被用到。</p> <h3 id="feed-forward-network"><a href="#feed-forward-network" class="header-anchor">#</a> Feed-Forward Network</h3> <p>第二个 sub-layer 是一个前馈网络：</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>FFN</mtext><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>x</mi><msub><mi>W</mi><mn>1</mn></msub><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><mo stretchy="false">)</mo><msub><mi>W</mi><mn>2</mn></msub><mo>+</mo><msub><mi>b</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\text{FFN} = \max(0, xW_1 + b_1) W_2 + b_2
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord">FFN</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">x</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p> <h2 id="decoder"><a href="#decoder" class="header-anchor">#</a> Decoder</h2> <p>encoder-decoder 结构：</p> <p><img src="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/img/encoder-decoder.cfe8e2a7.png" alt="encoder-decoder"></p> <p class="desc">图片来源：<a href="http://jalammar.github.io/illustrated-transformer#the-residuals" target="_blank">The Illustrated Transformer</a></p> <p><a href="http://jalammar.github.io/illustrated-transformer#the-decoder-side" target="_blank" rel="noopener noreferrer">这里</a>还有两个清楚的解释了 encoder 和 decoder 的工作方式的动画。</p> <p>decoder 也由 N = 6 个相同的 layer 堆叠而成，每个 layer 由三个 sub-layer 组成：</p> <img src="/img/in-post/2020-07-17/decoder.png" width="180px" alt="decoder"> <h3 id="masked-multi-head-self-attention"><a href="#masked-multi-head-self-attention" class="header-anchor">#</a> Masked Multi-Head Self-Attention</h3> <p>在训练时，decoder 在预测第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span> 个位置时不应该看到未来的信息，但 self-attention 机制能让它看到全局信息（标签泄露）。所以会对在 self-attention 的 softmax 层前加 mask，将未来信息屏蔽掉。</p> <p>mask 是一个下三角矩阵，对角线以及对角线左下都是1，其余都是0：</p> <img src="/img/in-post/2020-07-17/mask.png" width="300px" alt="mask"> <p class="desc">mask 矩阵，蓝色部分是 1，白色部分是 0（图片来源：<a href="https://spaces.ac.cn/archives/6933#单向语言模型" target="_blank">从语言模型到 Seq2Seq：Transformer 如戏，全靠 Mask</a>）</p> <p>矩阵的行为当前预测到第几个单词，列为当前允许看到前几个位置的信息。然后 mask=0 的位置上的元素会都被替换为 <code>-inf</code>。</p> <h3 id="multi-head-attention"><a href="#multi-head-attention" class="header-anchor">#</a> Multi-head Attention</h3> <p>即论文 3.2.3 节中的 encoder-decoder attention。它的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span></span></span></span> 来自于上一位置的 decoder 的输出（第一个 layer）或上一个 decoder layer 的输出（之后的 layer），而 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span> 来自于 encoder 的输出。这让 decoder 的每一个位置都可以看到到输入序列的全局信息。</p> <p>编码可以并行计算，但解码时，因为需要上一时刻的输出当作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span></span></span></span>，所以无法并行计算。</p> <h3 id="feed-forward-network-2"><a href="#feed-forward-network-2" class="header-anchor">#</a> Feed-Forward Network</h3> <p>同 encoder。</p> <h2 id="summary"><a href="#summary" class="header-anchor">#</a> Summary</h2> <p>优点：</p> <ul><li><p>相比其他方法，当序列长度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span> 小于词向量维度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span></span></span></span> 时，每层的计算复杂度（complexity per layer）更低：</p> <p><img src="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/img/complexity.41666cb8.png" alt="complexity"></p></li> <li><p>更好的并行性，符合目前的硬件（GPU）环境</p></li> <li><p>更好地处理长时依赖问题：如果要处理一个长度为 n 的序列，CNN 需要增加卷积层数来扩大视野，RNN 需要从 1 到 n 逐个进行计算，而 self-attention 只需要一步矩阵运算就可以</p></li></ul> <p>缺点：</p> <ul><li><p>但同时从上面那张复杂度表里也能看出来，当句子太长时，Transformer <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n^2)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 的时间复杂度是非常爆炸的。Transformer 能更好地处理长时依赖问题，但这种复杂度又让它没法处理太长的文本，即使是 Bert 的最大长度也只有 512。</p> <p>于是出现了一堆致力于解决这个问题的后续工作，等我摸两天鱼再看看有没有空写这个...</p></li> <li><p>扔掉了 RNN 和 CNN，导致失去了捕捉局部特征的能力</p> <p>不过论文也提到了一个 restricted self-attention（上面那张复杂度表里有），它假设当前词只与前后 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> 个词有关，因此只在这 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>r</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">2r+1</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> 个词上做 attention，复杂度是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi>r</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(nr)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">)</span></span></span></span>，相当于是在捕捉局部特征。听上去很像卷积窗口？</p></li> <li><p>失去的位置信息非常重要，在词向量中加入 position embedding 这个解决方案依然不够好</p></li> <li><p>非图灵完备（computationally universal）</p> <p><a href="https://openreview.net/pdf?id=HyzdRiR9Y7" target="_blank" rel="noopener noreferrer"><strong>Universal Transformer</strong></a>. <em>Mostafa Dehghani, et al.</em> ICLR 2019.</p></li></ul> <h2 id="reference"><a href="#reference" class="header-anchor">#</a> Reference</h2> <ul><li><p>图解 Transformer：<a href="http://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener noreferrer">The Illustrated Transformer</a></p></li> <li><p>连着代码一起讲：<a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html" target="_blank" rel="noopener noreferrer">The Annotated Transformer</a></p></li> <li><p><a href="https://zhuanlan.zhihu.com/p/44121378" target="_blank" rel="noopener noreferrer">【NLP】Transformer 详解</a></p></li> <li><p><a href="https://zhuanlan.zhihu.com/p/48508221" target="_blank" rel="noopener noreferrer">详解 Transformer（Attention Is All You Need）</a></p></li></ul></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/Renovamen/renovamen.github.io/edit/main/blog/posts/2020-07-17-transformer.md" target="_blank" rel="noopener noreferrer"><svg aria-hidden="true" width="14.4" height="14.4" viewBox="0 0 512 512" focusable="false" class="v-icon" style="font-size:0.9em;"><g><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3 0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9 0l60.1 60.1c18.8 18.7 18.8 49.1 0 67.9zM284.2 99.8c4.7-4.7 12.3-4.7 17.1 0l111 111c4.7 4.7 4.7 12.3 0 17l-262.6 262.6-121.5 21.3c-16.4 2.8-30.7-11.4-27.8-27.8l21.2-121.5zM124.1 339.9c5.5 5.5 14.3 5.5 19.8 0l154-154c5.5-5.5 5.5-14.3 0-19.8s-14.3-5.5-19.8 0l-154 154c-5.5 5.5-5.5 14.3 0 19.8zM88 424v-48h-36.3l-11.3 64.5 31.1 31.1 64.5-11.3v-36.3h-48z"></path></g></svg>
      Edit this page on GitHub
    </a></div> <div class="last-updated"><span class="prefix">Last Updated:</span> <span class="time">12/5/2020, 5:06:58 PM</span></div></footer> <!----> <div class="pager"><a href="/post/2020/07/10/messy-notes-nlp/" class="previous">
        Previous<br> <span>乱七八糟的知识点</span></a> <a href="/post/2020/08/05/meta-learning/" class="next">
        Previous<br> <span>元学习：一种套娃算法</span></a></div> <!----></main> <ul class="catalog-wrapper" style="top:0px !important;" data-v-628ec192><li class="level-2 toc-link-position-embedding" data-v-628ec192>Position Embedding</li><li class="level-2 toc-link-encoder" data-v-628ec192>Encoder</li><li class="level-3 toc-link-muti-head-self-attention" data-v-628ec192>Muti-Head Self-Attention</li><li class="level-3 toc-link-feed-forward-network" data-v-628ec192>Feed-Forward Network</li><li class="level-2 toc-link-decoder" data-v-628ec192>Decoder</li><li class="level-3 toc-link-masked-multi-head-self-attention" data-v-628ec192>Masked Multi-Head Self-Attention</li><li class="level-3 toc-link-multi-head-attention" data-v-628ec192>Multi-head Attention</li><li class="level-3 toc-link-feed-forward-network-2" data-v-628ec192>Feed-Forward Network</li><li class="level-2 toc-link-summary" data-v-628ec192>Summary</li><li class="level-2 toc-link-reference" data-v-628ec192>Reference</li></ul> <div class="search-page" data-v-2964d8cc><svg aria-hidden="true" width="26.599999999999998" height="30.4" viewBox="0 0 448 512" focusable="false" class="v-icon" style="font-size:1.9em;"><g><path d="M207 381.5l-194.3-194.4c-9.4-9.4-9.4-24.6 0-33.9l22.7-22.7c9.4-9.4 24.5-9.4 33.9 0l154.7 154 154.7-154c9.4-9.3 24.5-9.3 33.9 0l22.7 22.7c9.4 9.4 9.4 24.6 0 33.9l-194.3 194.4c-9.4 9.4-24.6 9.4-34 0z"></path></g></svg> <div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div></div> <div class="menu-btn-container" data-v-2964d8cc><div class="menu-btn-wrapper"><div class="menu-btn"><div class="menu-btn-icon" style="display:;"><span></span> <span></span> <span></span></div> <div class="menu-text" style="display:none;">0</div> <svg class="menu-svg"><circle cx="50%" cy="50%" r="48%" class="menu-border" style="stroke-dasharray:0% 314.15926%;"></circle></svg></div> <div class="menu-btn-child-wrapper"><a role="button" aria-label="Toggle light" title="Toggle light" class="toggle-mode menu-btn-child"><svg aria-hidden="true" width="16" height="16" viewBox="0 0 512 512" focusable="false" class="v-icon"><g><path d="M224 96l-16-32-32-16 32-16 16-32 16 32 32 16-32 16zM80 160l-26.7-53.3-53.3-26.7 53.3-26.7 26.7-53.3 26.7 53.3 53.3 26.7-53.3 26.7zM432 288l26.7 53.3 53.3 26.7-53.3 26.7-26.7 53.3-26.7-53.3-53.3-26.7 53.3-26.7zM502.6 94.2c12.5 12.5 12.5 32.8 0 45.3l-363.1 363.1c-6.3 6.3-14.4 9.4-22.7 9.4-8.2 0-16.4-3.1-22.6-9.4l-84.8-84.8c-12.5-12.5-12.5-32.8 0-45.3l363.1-363.1c6.3-6.3 14.4-9.4 22.7-9.4 8.2 0 16.4 3.1 22.6 9.4zM359.4 203.5l86.6-86.6-50.9-50.9-86.6 86.5z"></path></g></svg></a> <div class="menu-btn-child"><svg aria-hidden="true" width="14" height="16" viewBox="0 0 448 512" focusable="false" class="v-icon"><g><path d="M207 381.5l-194.3-194.4c-9.4-9.4-9.4-24.6 0-33.9l22.7-22.7c9.4-9.4 24.5-9.4 33.9 0l154.7 154 154.7-154c9.4-9.3 24.5-9.3 33.9 0l22.7 22.7c9.4 9.4 9.4 24.6 0 33.9l-194.3 194.4c-9.4 9.4-24.6 9.4-34 0z"></path></g></svg></div> <div class="menu-btn-child"><svg aria-hidden="true" width="14" height="16" viewBox="0 0 448 512" focusable="false" class="v-icon"><g><path d="M241 130.5l194.3 194.4c9.4 9.4 9.4 24.6 0 33.9l-22.7 22.7c-9.4 9.4-24.5 9.4-33.9 0l-154.7-154-154.7 154c-9.4 9.3-24.5 9.3-33.9 0l-22.7-22.7c-9.4-9.4-9.4-24.6 0-33.9l194.3-194.4c9.4-9.4 24.6-9.4 34 0z"></path></g></svg></div> <div class="menu-btn-child menu-toc-btn"><svg aria-hidden="true" width="16" height="16" viewBox="0 0 512 512" focusable="false" class="v-icon"><g><path d="M48 48c26.5 0 48 21.5 48 48s-21.5 48-48 48-48-21.5-48-48 21.5-48 48-48zM48 208c26.5 0 48 21.5 48 48s-21.5 48-48 48-48-21.5-48-48 21.5-48 48-48zM48 368c26.5 0 48 21.5 48 48s-21.5 48-48 48-48-21.5-48-48 21.5-48 48-48zM496 384c8.8 0 16 7.2 16 16v32c0 8.8-7.2 16-16 16h-320c-8.8 0-16-7.2-16-16v-32c0-8.8 7.2-16 16-16h320zM496 64c8.8 0 16 7.2 16 16v32c0 8.8-7.2 16-16 16h-320c-8.8 0-16-7.2-16-16v-32c0-8.8 7.2-16 16-16h320zM496 224c8.8 0 16 7.2 16 16v32c0 8.8-7.2 16-16 16h-320c-8.8 0-16-7.2-16-16v-32c0-8.8 7.2-16 16-16h320z"></path></g></svg></div> <div class="menu-btn-child menu-btn-sidebar"><svg aria-hidden="true" width="16" height="16" viewBox="0 0 512 512" focusable="false" class="v-icon"><g><path d="M464 0c26.5 0 48 21.5 48 48v320c0 26.5-21.5 48-48 48h-48v48c0 26.5-21.5 48-48 48h-320c-26.5 0-48-21.5-48-48v-320c0-26.5 21.5-48 48-48h48v-48c0-26.5 21.5-48 48-48h320zM368 464v-208h-320v208h320zM464 368v-320h-320v48h224c26.5 0 48 21.5 48 48v224h48z"></path></g></svg></div></div></div></div> <div class="footer-wrapper footer" data-v-48eb48db data-v-2964d8cc><span data-v-48eb48db>
      &copy; <a href="https://github.com/Renovamen" target="_blank">Renovamen</a> 2018-2020
      <br>
      Powered by <a href="https://vuepress.vuejs.org" target="_blank">VuePress</a> &
      <a href="https://github.com/Renovamen/vuepress-theme-gungnir" target="_blank">Gungnir</a>
    </span></div></div><div class="global-ui"></div></div>
    <script src="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/app.293b3460.js" defer></script><script src="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/9.1660df00.js" defer></script><script src="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/1.bee6a65f.js" defer></script><script src="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/2.559efb66.js" defer></script><script src="https://cdn.jsdelivr.net/gh/Renovamen/renovamen.github.io@gh-pages/assets/js/10.2b27df40.js" defer></script>
  </body>
</html>
