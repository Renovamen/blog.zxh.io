<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
    <meta name="description" content="Xiaohan Zou's blog">
    <meta name="keywords"  content="">
    <meta name="theme-color" content="#000000">
    
    <!-- Open Graph -->
    <meta property="og:title" content="三月大锅烩 - Renovamen (Xiaohan Zou)">
    
    <meta property="og:type" content="article">
    <meta property="og:description" content="Machine Translation
">
    
    <meta property="article:published_time" content="2020-03-17T00:00:00Z">
    
    
    <meta property="article:author" content="Renovamen">
    
    
    <meta property="article:tag" content="NLP">
    
    <meta property="article:tag" content="CV">
    
    <meta property="article:tag" content="Machine Translation">
    
    <meta property="article:tag" content="Text Classification">
    
    <meta property="article:tag" content="Image Captioning">
    
    <meta property="article:tag" content="Image Aesthetic Captioning">
    
    
    <meta property="og:image" content="https://renovamen.inkimg/header-avatar.jpeg">
    <meta property="og:url" content="https://renovamen.ink/2020/03/17/papers-reading/">
    <meta property="og:site_name" content="Renovamen (Xiaohan Zou)">
    
    <title>三月大锅烩 - Renovamen (Xiaohan Zou)</title>

    <!-- Web App Manifest -->
    <link rel="manifest" href="/pwa/manifest.json">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/img/favicon.svg">
    
    <!-- Canonical URL -->
    <link rel="canonical" href="https://renovamen.ink/2020/03/17/papers-reading/"><!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@3.3.2/dist/css/bootstrap.min.css">
    
    <!-- Fonts -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700,200"/>

    <!-- Custom Fonts -->
    <link href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" rel="stylesheet" type="text/css">
    
    <!-- Font Awesome Animation -->
    <link href="https://cdn.jsdelivr.net/npm/font-awesome-animation@0.2.1/dist/font-awesome-animation.min.css" rel="stylesheet" type="text/css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/gungnir.css">
    
    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>

    <!-- jQuery -->
    <script src="https://cdn.jsdelivr.net/npm/jquery@2.1.3/dist/jquery.min.js"></script>

    <!-- Lazyload (.js & .css)-->
    <script>// https://github.com/rgrove/lazyload

/*jslint browser: true, eqeqeq: true, bitwise: true, newcap: true, immed: true, regexp: false */

/**
LazyLoad makes it easy and painless to lazily load one or more external
JavaScript or CSS files on demand either during or after the rendering of a web
page.
Supported browsers include Firefox 2+, IE6+, Safari 3+ (including Mobile
Safari), Google Chrome, and Opera 9+. Other browsers may or may not work and
are not officially supported.
Visit https://github.com/rgrove/lazyload/ for more info.
Copyright (c) 2011 Ryan Grove <ryan@wonko.com>
All rights reserved.
Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the 'Software'), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
the Software, and to permit persons to whom the Software is furnished to do so,
subject to the following conditions:
The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.
THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
@module lazyload
@class LazyLoad
@static
*/

LazyLoad = (function (doc) {
    // -- Private Variables ------------------------------------------------------
  
    // User agent and feature test information.
    var env,
  
    // Reference to the <head> element (populated lazily).
    head,
  
    // Requests currently in progress, if any.
    pending = {},
  
    // Number of times we've polled to check whether a pending stylesheet has
    // finished loading. If this gets too high, we're probably stalled.
    pollCount = 0,
  
    // Queued requests.
    queue = {css: [], js: []},
  
    // Reference to the browser's list of stylesheets.
    styleSheets = doc.styleSheets;
  
    // -- Private Methods --------------------------------------------------------
  
    /**
    Creates and returns an HTML element with the specified name and attributes.
    @method createNode
    @param {String} name element name
    @param {Object} attrs name/value mapping of element attributes
    @return {HTMLElement}
    @private
    */
    function createNode(name, attrs) {
        var node = doc.createElement(name), attr;
    
        for (attr in attrs) {
            if (attrs.hasOwnProperty(attr)) {
                node.setAttribute(attr, attrs[attr]);
            }
        }
    
        return node;
    }
  
    /**
    Called when the current pending resource of the specified type has finished
    loading. Executes the associated callback (if any) and loads the next
    resource in the queue.
    @method finish
    @param {String} type resource type ('css' or 'js')
    @private
    */
    function finish(type) {
        var p = pending[type],
            callback,
            urls;
    
        if (p) {
            callback = p.callback;
            urls     = p.urls;
    
            urls.shift();
            pollCount = 0;
    
            // If this is the last of the pending URLs, execute the callback and
            // start the next request in the queue (if any).
            if (!urls.length) {
                callback && callback.call(p.context, p.obj);
                pending[type] = null;
                queue[type].length && load(type);
            }
        }
    }
  
    /**
    Populates the <code>env</code> variable with user agent and feature test
    information.
    @method getEnv
    @private
    */
    function getEnv() {
        var ua = navigator.userAgent;
    
        env = {
            // True if this browser supports disabling async mode on dynamically
            // created script nodes. See
            // http://wiki.whatwg.org/wiki/Dynamic_Script_Execution_Order
            async: doc.createElement('script').async === true
        };
    
        (env.webkit = /AppleWebKit\//.test(ua))
            || (env.ie = /MSIE|Trident/.test(ua))
            || (env.opera = /Opera/.test(ua))
            || (env.gecko = /Gecko\//.test(ua))
            || (env.unknown = true);
    }
  
    /**
    Loads the specified resources, or the next resource of the specified type
    in the queue if no resources are specified. If a resource of the specified
    type is already being loaded, the new request will be queued until the
    first request has been finished.
    When an array of resource URLs is specified, those URLs will be loaded in
    parallel if it is possible to do so while preserving execution order. All
    browsers support parallel loading of CSS, but only Firefox and Opera
    support parallel loading of scripts. In other browsers, scripts will be
    queued and loaded one at a time to ensure correct execution order.
    @method load
    @param {String} type resource type ('css' or 'js')
    @param {String|Array} urls (optional) URL or array of URLs to load
    @param {Function} callback (optional) callback function to execute when the
      resource is loaded
    @param {Object} obj (optional) object to pass to the callback function
    @param {Object} context (optional) if provided, the callback function will
      be executed in this object's context
    @private
    */
    function load(type, urls, callback, obj, context) {
        var _finish = function () { finish(type); },
            isCSS   = type === 'css',
            nodes   = [],
            i, len, node, p, pendingUrls, url;
  
        env || getEnv();
  
        if (urls) {
            // If urls is a string, wrap it in an array. Otherwise assume it's an
            // array and create a copy of it so modifications won't be made to the
            // original.
            urls = typeof urls === 'string' ? [urls] : urls.concat();
    
            // Create a request object for each URL. If multiple URLs are specified,
            // the callback will only be executed after all URLs have been loaded.
            //
            // Sadly, Firefox and Opera are the only browsers capable of loading
            // scripts in parallel while preserving execution order. In all other
            // browsers, scripts must be loaded sequentially.
            //
            // All browsers respect CSS specificity based on the order of the link
            // elements in the DOM, regardless of the order in which the stylesheets
            // are actually downloaded.
            if (isCSS || env.async || env.gecko || env.opera) {
                // Load in parallel.
                queue[type].push({
                    urls    : urls,
                    callback: callback,
                    obj     : obj,
                    context : context
                });
            } 
            else {
                // Load sequentially.
                for (i = 0, len = urls.length; i < len; ++i) {
                    queue[type].push({
                        urls    : [urls[i]],
                        callback: i === len - 1 ? callback : null, // callback is only added to the last URL
                        obj     : obj,
                        context : context
                    });
                }
            }
        }
  
        // If a previous load request of this type is currently in progress, we'll
        // wait our turn. Otherwise, grab the next item in the queue.
        if (pending[type] || !(p = pending[type] = queue[type].shift())) {
            return;
        }
    
        head || (head = doc.head || doc.getElementsByTagName('head')[0]);
        pendingUrls = p.urls.concat();

        for (i = 0, len = pendingUrls.length; i < len; ++i) {
            url = pendingUrls[i];
    
            if (isCSS) {
                node = env.gecko ? createNode('style') : createNode('link', {
                    href: url,
                    rel : 'stylesheet'
                });
            } 
            else {
                node = createNode('script', {src: url});
                node.async = false;
            }
    
            node.className = 'lazyload';
            node.setAttribute('charset', 'utf-8');
    
            if (env.ie && !isCSS && 'onreadystatechange' in node && !('draggable' in node)) {
                node.onreadystatechange = function () {
                    if (/loaded|complete/.test(node.readyState)) {
                        node.onreadystatechange = null;
                        _finish();
                    }
                };
            } 
            else if (isCSS && (env.gecko || env.webkit)) {
                // Gecko and WebKit don't support the onload event on link nodes.
                if (env.webkit) {
                    // In WebKit, we can poll for changes to document.styleSheets to
                    // figure out when stylesheets have loaded.
                    p.urls[i] = node.href; // resolve relative URLs (or polling won't work)
                    pollWebKit();
                } 
                else {
                    // In Gecko, we can import the requested URL into a <style> node and
                    // poll for the existence of node.sheet.cssRules. Props to Zach
                    // Leatherman for calling my attention to this technique.
                    node.innerHTML = '@import "' + url + '";';
                    pollGecko(node);
                }
            } 
            else {
                node.onload = node.onerror = _finish;
            }
    
            nodes.push(node);
        }
    
        for (i = 0, len = nodes.length; i < len; ++i) {
            head.appendChild(nodes[i]);
        }
    }
  
    /**
    Begins polling to determine when the specified stylesheet has finished loading
    in Gecko. Polling stops when all pending stylesheets have loaded or after 10
    seconds (to prevent stalls).
    Thanks to Zach Leatherman for calling my attention to the @import-based
    cross-domain technique used here, and to Oleg Slobodskoi for an earlier
    same-domain implementation. See Zach's blog for more details:
    http://www.zachleat.com/web/2010/07/29/load-css-dynamically/
    @method pollGecko
    @param {HTMLElement} node Style node to poll.
    @private
    */
    function pollGecko(node) {
        var hasRules;
    
        try {
            // We don't really need to store this value or ever refer to it again, but
            // if we don't store it, Closure Compiler assumes the code is useless and
            // removes it.
            hasRules = !!node.sheet.cssRules;
        } 
        catch (ex) {
            // An exception means the stylesheet is still loading.
            pollCount += 1;

            if (pollCount < 200) {
                setTimeout(function () { pollGecko(node); }, 50);
            } 
            else {
                // We've been polling for 10 seconds and nothing's happened. Stop
                // polling and finish the pending requests to avoid blocking further
                // requests.
                hasRules && finish('css');
            }
            return;
        }
    
        // If we get here, the stylesheet has loaded.
        finish('css');
    }
    
    /**
    Begins polling to determine when pending stylesheets have finished loading
    in WebKit. Polling stops when all pending stylesheets have loaded or after 10
    seconds (to prevent stalls).
    @method pollWebKit
    @private
    */
    function pollWebKit() {
        var css = pending.css, i;

        if (css) {
            i = styleSheets.length;

            // Look for a stylesheet matching the pending URL.
            while (--i >= 0) {
                if (styleSheets[i].href === css.urls[0]) {
                    finish('css');
                    break;
                }
            }

            pollCount += 1;
    
            if (css) {
                if (pollCount < 200) {
                    setTimeout(pollWebKit, 50);
                } 
                else {
                    // We've been polling for 10 seconds and nothing's happened, which may
                    // indicate that the stylesheet has been removed from the document
                    // before it had a chance to load. Stop polling and finish the pending
                    // request to prevent blocking further requests.
                    finish('css');
                }
            }
        }
    }
    
    return {
    
        /**
         Requests the specified CSS URL or URLs and executes the specified
        callback (if any) when they have finished loading. If an array of URLs is
        specified, the stylesheets will be loaded in parallel and the callback
        will be executed after all stylesheets have finished loading.
        @method css
        @param {String|Array} urls CSS URL or array of CSS URLs to load
        @param {Function} callback (optional) callback function to execute when
        the specified stylesheets are loaded
        @param {Object} obj (optional) object to pass to the callback function
        @param {Object} context (optional) if provided, the callback function
        will be executed in this object's context
        @static
        */
        css: function (urls, callback, obj, context) {
            load('css', urls, callback, obj, context);
        },
    
        /**
         Requests the specified JavaScript URL or URLs and executes the specified
        callback (if any) when they have finished loading. If an array of URLs is
        specified and the browser supports it, the scripts will be loaded in
        parallel and the callback will be executed after all scripts have
        finished loading.
        Currently, only Firefox and Opera support parallel loading of scripts while
        preserving execution order. In other browsers, scripts will be
        queued and loaded one at a time to ensure correct execution order.
        @method js
        @param {String|Array} urls JS URL or array of JS URLs to load
        @param {Function} callback (optional) callback function to execute when
        the specified scripts are loaded
        @param {Object} obj (optional) object to pass to the callback function
        @param {Object} context (optional) if provided, the callback function
        will be executed in this object's context
        @static
        */
        js: function (urls, callback, obj, context) {
            load('js', urls, callback, obj, context);
        }
    };
})(this.document);</script>
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- Renovamen: add menu button -->
    <div class="menu-btn-container">
    <div class="menu-btn-wrapper">
        <div class="menu-btn">
            <div class="menu-btn-icon">
                <span></span>
                <span></span>
                <span></span>
            </div>
            <div class="menu-text"></div>
            <svg class="menu-svg">
                <circle class="menu-border" cx="50%" cy="50%" r="48%"></circle>
            </svg>
        </div>
        <div class="menu-btn-child-wrapper">
            <div class="menu-btn-child" id="menu-theme-btn">
                <span class="fa icon-theme"></span>
            </div>
            <div class="menu-btn-child" onclick="smoothTo('bottom')">
                <i class="fas fa-chevron-down"></i>
            </div>
            <div class="menu-btn-child" onclick="smoothTo('top')">
                <i class="fas fa-chevron-up"></i>
            </div>
            
            
            <div class="menu-btn-child" id="menu-toc-btn">
                <i class="fas fa-list-ul"></i>
            </div>
            
            
            <div class="menu-btn-child" id="menu-navbar-btn">
                <i class="far fa-window-restore"></i>
            </div>
        </div>
    </div>
</div>

<script type="text/javascript">
    // open menu
    $('.menu-btn').click(function() {
        $('.menu-btn-container').toggleClass('open');
    });
    
    // open navbar
    $('#menu-navbar-btn').click(function() {
        mobileNavToggle();
    });

    // open catalog
    $('#menu-toc-btn').click(function() {
        $('.side-catalog').toggleClass('open');
    });

    // set theme icon in menu
    function setThemeIcon(newTheme) {
        const icons = {
            'light': '"\\f185"', 
            'dark': '"\\f186"', 
            'sepia': '"\\f0f4"'
        }
        $('#menu-theme-btn').append(
            '<style>.icon-theme:before{content:' + icons[newTheme] + '}</style>'
        );
    }

    function toggleTheme() {
        const themes = ['light', 'dark', 'sepia']
        // get current theme
        const currentTheme = window.__theme
        const currentIndex = themes.indexOf(currentTheme)
        // set next theme
        const nextIndex = (currentIndex + 1) % themes.length
        const nextTheme = themes[nextIndex]
        window.__setPreferredTheme(nextTheme)
        setThemeIcon(nextTheme)
    }

    // change theme
    $('#menu-theme-btn').click(function() {
        toggleTheme()
    });
</script>

    <div class="main-container">
    <!-- Navigation -->

<nav class="navbar navbar-default navbar-custom navbar-fixed-top invert">

    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <!-- navbar toggle for old mobile menu button (by Hux) -->
            <!-- <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button> -->
            <a class="navbar-brand" href="/">$ cd /home/</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">

                    
                    <li>
                        
                        <a href="/" class="faa-parent animated-hover">
                        
                            
                            <i class="fab fa-fort-awesome fa-lg faa-wrench"></i>
                            
                            Home
                        </a>
                        
                    </li>
                    
                    <li>
                        
                        <a href="/about/" class="faa-parent animated-hover">
                        
                            
                            <i class="fas fa-paw fa-lg faa-wrench"></i>
                            
                            About
                        </a>
                        
                    </li>
                    
                    <li>
                        
                        <a href="/archive/" class="faa-parent animated-hover">
                        
                            
                            <i class="fas fa-archive fa-lg faa-wrench"></i>
                            
                            Archive
                        </a>
                        
                    </li>
                    
                    <li>
                        
                        <a href="/links/" class="faa-parent animated-hover">
                        
                            
                            <i class="fas fa-link fa-lg faa-wrench"></i>
                            
                            Links
                        </a>
                        
                    </li>
                    
                    <li>
                        <a id="search-btn" class="faa-parent animated-hover">
                            <i class="fas fa-search fa-lg faa-wrench"></i> Search
                        </a>
                    </li>
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>

<!-- Old Mobile Navbar Script (By Hux) -->
<!-- <script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    var __HuxNav__ = {
        close: function(){
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        },
        open: function(){
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }

    // Bind Event
    $toggle.addEventListener('click', function(e){
        if ($navbar.className.indexOf('in') > 0) {
            __HuxNav__.close()
        }else{
            __HuxNav__.open()
        }
    })

    /**
     * Since Fastclick is used to delegate 'touchstart' globally
     * to hack 300ms delay in iOS by performing a fake 'click',
     * Using 'e.stopPropagation' to stop 'touchstart' event from 
     * $toggle/$collapse will break global delegation.
     * 
     * Instead, we use a 'e.target' filter to prevent handler
     * added to document close HuxNav.  
     *
     * Also, we use 'click' instead of 'touchstart' as compromise
     */
    document.addEventListener('click', function(e){
        if(e.target == $toggle) return;
        if(e.target.className == 'icon-bar') return;
        __HuxNav__.close();
    })
</script> -->

    <!-- Image to hack wechat -->
<!-- <img src="/img/in-post/2020-03-17/header.jpg" width="0" height="0"> -->

<!-- Post Header -->



    
    <style type="text/css">
        header.intro-header{
            position: relative;
            background-image: url('/img/in-post/2020-03-17/header.jpg');
            background: ;
        }

        
    </style>
    
    





<header class="intro-header style-text" >

    <div class="header-mask"></div>
    
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/archive/?tag=NLP" title="NLP">NLP</a>
                        
                        <a class="tag" href="/archive/?tag=CV" title="CV">CV</a>
                        
                        <a class="tag" href="/archive/?tag=Machine+Translation" title="Machine Translation">Machine Translation</a>
                        
                        <a class="tag" href="/archive/?tag=Text+Classification" title="Text Classification">Text Classification</a>
                        
                        <a class="tag" href="/archive/?tag=Image+Captioning" title="Image Captioning">Image Captioning</a>
                        
                        <a class="tag" href="/archive/?tag=Image+Aesthetic+Captioning" title="Image Aesthetic Captioning">Image Aesthetic Captioning</a>
                        
                    </div>
                    <h1>三月大锅烩</h1>
                    
                    <h2 class="subheading">Papers Reading: Machine Translation / Text Classification / Image Captioning</h2>
                    
                    <span class="meta">Posted by Renovamen on March 17, 2020</span>
                    
                </div>
            </div>
        </div>
    </div>
</header>











<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

    <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <!-- Multi-Lingual -->
                

				<h2 id="machine-translation">Machine Translation</h2>

<p>给定源语言句子 \(x\)，目标是最大化其对应的目标语言翻译 \(y\) 的概率，即：</p>

\[\hat{y} = \arg \max_y p(y \mid x)\]

<h3 id="seq2seq">Seq2Seq</h3>

<p><strong>Sequence to Sequence Learning with Neural Networks.</strong> <em>Ilya Sutskeve, Oriol Vinyals and Quoc V. Le.</em> NIPS 2014. <a href="https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf" target="_blank">[Paper]</a></p>

<p>提出了 Sequence to Sequence 框架，由一个 encoder 和一个 decoder 组成。</p>

<p><img src="/img/in-post/2020-03-17/machine-translation/seq2seq.png" alt="seq2seq" /></p>

<h4 id="encoder">Encoder</h4>

<p>一个 LSTM，用于把源语言句子 \(x = (x_1, ... , x_{T_x})\) 编码成一个固定长度的向量 \(c\)：</p>

\[h_t = f_1 (x_t, h_{t−1})\]

\[c = h_{T_x}\]

<p>即 LSTM 最后一个时间步输出的隐状态就是句子编码后的向量。&lt;EOS&gt; 是终止符，不用编码。</p>

<h4 id="decoder">Decoder</h4>

<p>一个 LSTM，用于生成目标语言翻译 \(y = (y_1, ... , y_{T_y})\)，第一个时间步的输入是 \(c\)，生成终止符 &lt;EOS&gt; 后停止句子生成。</p>

<p>把<a href="#machine-translation">上述</a>联合概率用链式法则分解后得到：</p>

\[p(y) = \prod_{t=1}^T p(y_t \mid \{ y_1, ..., y_{t-1} \}, c)\]

<p>每个时间步的条件概率为：</p>

\[p(y_t \mid \{ y_1, ..., y_{t-1} \}, c) = g(y_{t-1}, s_t, c)\]

\[s_i = f_2 (s_{i−1}, y_{i−1})\]

<p>\(g\) 是一个非线性函数，用于输出单词 \(y_t\) 的概率（比如 softmax），\(s_t\) 是 LSTM（decoder）在 \(t\) 时刻的隐状态。</p>

<h3 id="seq2seq--attention">Seq2Seq + Attention</h3>

<p><strong>Neural Machine Translation by Jointly Learning to Align and Translate.</strong> <em>Dzmitry Bahdanau, Kyunghyun Cho and Yoshua Bengio.</em> ICLR 2015. <a href="https://arxiv.org/pdf/1409.0473.pdf" target="_blank">[arXiv]</a></p>

<p>首次把 attention 引入 seq2seq。</p>

<p><img src="/img/in-post/2020-03-17/machine-translation/seq2seq-attention.png" alt="seq2seq attention" width="450px" /></p>

<h4 id="encoder-1">Encoder</h4>

<p>encoder 是一个 BiLSTM，即有两个 LSTM：</p>

<ul>
  <li>
    <p>第一个把源句子正向输入（\(x_1 \rightarrow x_{T_x}\)），所有时间步输出的隐状态为 \((\overrightarrow{h_1}, ... , \overrightarrow{h_{T_x}})\)</p>
  </li>
  <li>
    <p>第二个把源句子逆向输入（\(x_{T_x} \rightarrow x_1\)），所有时间步输出的隐状态为 \((\overleftarrow{h_1}, ... , \overleftarrow{h_{T_x}})\)</p>
  </li>
</ul>

<p>最终，encoder 每个时间步的输出就是把 \(\overrightarrow{h_j}\) 和 \(\overleftarrow{h_j}\) 拼起来：</p>

\[h_j = [\overrightarrow{h_j}; \overleftarrow{h_j}]\]

<p>所有时间步的输出为：</p>

\[(h_1, ..., h_{T_x})\]

<h4 id="decoder-1">Decoder</h4>

<p>把每个时间步的条件概率定义为：</p>

\[p(y_i \mid y_1, ... , y_{i−1}, x) = g(y_{i−1}, s_i, c_i)\]

<p>\(s_i\) 是 LSTM 在 \(i\) 时刻的隐状态：</p>

\[s_i = f(s_{i−1}, y_{i−1}, c_i)\]

<p>\(c_i\) 是 \(i\) 时刻的 context vector，通过把 encoder 每个时间步的输出向量加权平均得到：</p>

\[c_i = \sum_{j=1}^{T_x} \alpha_{ij} h_j\]

<p>\(\alpha_{ij}\) 是 \(h_j\) 的权重，计算公式为：</p>

\[e_{ij} = a(s_{i−1}, h_j)\]

\[\alpha_{ij} = \frac{\exp (e_{ij})}{\sum_{k=1}^{T_x} \exp (e_{ik})}\]

<p>\(a\) 是一个 MLP，\(\alpha_{ij}\) 由 \(e_{ij}\) 归一化（softmax）后得到。相当于 \(\alpha_{ij}\) 代表了在生成第 \(i\) 个目标句子单词时，第 \(j\) 个源句子单词的重要性。</p>

<h3 id="unsupervised-nmt">Unsupervised NMT</h3>

<p><strong>Unsupervised Neural Machine Translation.</strong> <em>Mikel Artetxe, et al.</em> ICLR 2018. <a href="https://arxiv.org/pdf/1710.11041.pdf" target="_blank">[arXiv]</a> <a href="https://github.com/artetxem/undreamt" target="_blank">[Code]</a></p>

<p><strong>Unsupervised Machine Translation Using Monolingual Corpora Only.</strong> <em>Guillaume Lample, et al.</em> ICLR 2018. <a href="https://research.fb.com/wp-content/uploads/2018/03/unsupervised-machine-translation-using-monolingual-corpora-only.pdf" target="_blank">[Paper]</a></p>

<h2 id="text-classification">Text Classification</h2>

<h3 id="hierarchical-attention-network">Hierarchical Attention Network</h3>

<p><strong>Hierarchical Attention Networks for Document Classification.</strong> <em>Zichao Yang, et al.</em> NAACL 2016. <a href="https://www.aclweb.org/anthology/N16-1174.pdf" target="_blank">[Paper]</a></p>

<ul>
  <li>
    <p>用“词-句子-文档”的层次化结构来表示一篇文档，用词向量来表示句子向量，然后用句子向量来表示文档向量。</p>
  </li>
  <li>
    <p>两个层次的 attention (word attention 和 sentence attention)。动机是文档中不同的句子和单词的重要性不同，且词和句子的重要性依赖于上下文。</p>
  </li>
</ul>

<p><img src="/img/in-post/2020-03-17/text-classification/HAN.png" alt="HAN" width="450px" /></p>

<h4 id="word-encoder">Word Encoder</h4>

<p>双向 <a href="/2019/02/15/rnn-with-its-friends/#gru" target="_blank">GRU</a>：</p>

\[\overrightharpoon{h}_{it} = \overrightharpoon{\text{GRU}} (x_{it}), t \in [1, T]\]

\[\overleftharpoon{h}_{it} = \overleftharpoon{\text{GRU}} (x_{it}), t \in [T, 1]\]

\[h_{it} = [\overrightharpoon{h}_{it}; \overleftharpoon{h}_{it}]\]

<p>\(x_{ij} = W_e w_{ij}\) 是文档中第 \(i\) 个句子的第 \(t\) 个单词的词嵌入向量，\(T\) 为该句子中的单词个数。</p>

<h4 id="word-attention">Word Attention</h4>

<p>对每个 \(h_{it}\) 计算一个权重（MLP + softmax），然后加权平均得到句子向量 \(s_i\)：</p>

\[u_{it} = \text{tanh} (W_w h_{it} + b_w)\]

\[\alpha_{it} = \frac{\exp (u_{it}^{\top} u_w)}{\sum_t \exp (u_{it}^{\top} u_w)}\]

\[s_i = \sum_t \alpha_{it} h_{it}\]

<p>softmax 中，\(u_w\) 是一个随机初始化的 context vector，用于表示哪些词更重要。</p>

<h4 id="sentence-encoder">Sentence Encoder</h4>

<p>依然是双向 GRU，只不过输入为上一步得到的句子向量 \(s_i\)：</p>

\[\overrightharpoon{h}_i = \overrightharpoon{\text{GRU}} (s_i), t \in [1, L]\]

\[\overleftharpoon{h}_i = \overleftharpoon{\text{GRU}} (s_i), t \in [L, 1]\]

\[h_i = [\overrightharpoon{h}_i; \overleftharpoon{h}_i]\]

<p>其中，\(L\) 为文档中的句子个数。</p>

<h4 id="sentence-attention">Sentence Attention</h4>

<p>对每个 \(h_i\) 计算一个权重（MLP + softmax），然后加权平均得到文档向量 \(v\)：</p>

\[u_i = \text{tanh} (W_s h_i + b_s)\]

\[\alpha_{it} = \frac{\exp (u_i^{\top} u_s)}{\sum_t \exp (u_i^{\top} u_s)}\]

\[v = \sum_t \alpha_i h_i\]

<p>\(u_s\) 依然是是一个随机初始化的 context vector，用于表示哪些句子更重要。</p>

<h4 id="document-classification">Document Classification</h4>

<p>最后把文档向量 \(v\) 扔进 softmax 来进行分类：</p>

\[p = \text{softmax} (W_c v + b_c)\]

<p>损失函数为：</p>

\[L = - \sum_d \log p_{dj}\]

<p>\(p_{dj}\) 是文档 \(d\) 的真实标签 \(j\) 出现的概率。</p>

<h2 id="image-captioning">Image Captioning</h2>

<h3 id="show-and-tell">Show and Tell</h3>

<p><strong>Show and Tell: A Neural Image Caption Generator.</strong> <em>Oriol Vinyals, et al.</em> CVPR 2015. <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vinyals_Show_and_Tell_2015_CVPR_paper.pdf" target="_blank">[Paper]</a> <a href="https://github.com/tensorflow/models/tree/master/research/im2txt" target="_blank">[Code]</a></p>

<p>Google 出品，算是最早开用 CNN-LSTM 做 Image Captioning 这个坑的论文之一。</p>

<p><strong>P.S.</strong> 依然是在 CVPR 2015 上，Stanford 也发了篇模型核心结构差不多的论文：</p>

<p><strong>Deep Visual-semantic Alignments for Generating Image Descriptions.</strong> <em>Andrej Karpathy and Li Fei-Fei.</em> CVPR 2015. <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Karpathy_Deep_Visual-Semantic_Alignments_2015_CVPR_paper.pdf" target="_blank">[Paper]</a> <a href="https://github.com/karpathy/neuraltalk" target="_blank">[NeuralTalk]</a> <a href="https://github.com/karpathy/neuraltalk2" target="_blank">[NeuralTalk2]</a></p>

<p>但鉴于 NeuralTalk 的代码是用 Lua 和 Torch 写的，而我不会 Lua 和 Torch（…），所以这篇论文就没认真看……</p>

<h4 id="cnn-lstm">CNN-LSTM</h4>

<p><strong>模型目标：</strong></p>

\[\theta^* = \arg \max_{\theta} \sum_{(I,S)} \log p(S \mid I; \theta)\]

<p>\(\theta\) 是模型参数，\(I\) 是图像，\(S\) 是对应的正确的图像描述。也就是要最大化正确描述的概率。</p>

<p>为了解决解决 \(S\) 的长度不定的问题，用条件概率的链式法则来把上述联合概率分解成以下形式，这里为了方便扔掉了模型参数 \(\theta\)：</p>

\[\log p(S \mid I) = \sum_{t=0}^N \log p(S_t \mid I, S_0, ... , S_{t-1})\]

<p>\(S_0\) 是起始符，\(S_N\) 是终止符。如果生成了终止符，则该句子生成结束。</p>

<p><strong>LSTM：</strong></p>

<p>在 LSTM 中，每个时间步的条件概率可以表示为：</p>

\[\log p(S_t \mid S_1, ... , S_{t-1}, I) = k(h_t, z_t)\]

<p>\(k\) 是一个非线性函数，输出为单词 \(S_t\) 的概率。\(h_t\) 是 LSTM 在当前时间步的隐状态。\(z_t\) 是图像特征，在这里是 CNN 最后一个全连接层输出的一个向量；在加了 Attention 机制的 LSTM 中则是每个时间步对 CNN 最后一个卷积层输出的特征图进行 Attention 操作后得到的一个向量，依赖于 \(h_t\)。</p>

<p>新的 \(x_t\) 输入后，隐状态更新的公式为：</p>

\[h_{t} = f(x_t, h_{t-1}, c_{t-1})\]

<p>\(c_{t-1}\) 是 LSTM 在上一时间步的细胞状态。</p>

<p><strong>CNN：</strong></p>

<p>用来提图像特征的 CNN 直接用了 Inception V3：</p>

<p><strong>Rethinking the Inception Architecture for Computer Vision.</strong> <em>Christian Szegedy, et al.</em> CVPR 2016. <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf" target="_blank">[Paper]</a> <a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_v3.py" target="_blank">[Code]</a></p>

<h4 id="lstm">LSTM</h4>

<p>在<a href="/2019/02/15/rnn-with-its-friends/#lstm" target="_blank">另一篇文章</a>里理过 LSTM。</p>

<p><img src="/img/in-post/2020-03-17/img2txt/lstm.png" alt="LSTM" width="350px" /></p>

<h5 id="training">Training</h5>

<p>把 LSTM 按时间步展开就是这个样子：</p>

<p><img src="/img/in-post/2020-03-17/img2txt/cnn-lstm.png" alt="CNN-LSTM" width="450px" /></p>

<p>这样看起来就像一个前馈网络了。</p>

<p>假设输入的图片为 \(I\)，它的正确描述为 \(S = (S_0, ... , S_N )\)，则展开过程为：</p>

\[x_{-1} = \text{CNN}(I)\]

\[x_t = W_e S_t, t \in \{ 0 ... N-1 \}\]

\[p_{t+1} = \text{LSTM} (x_t), t \in \{ 0 ... N-1 \}\]

<p>其中，\(S_t\) 是经过独热编码的单词，都是 \(1 \times D\) 的向量，\(D\) 是词典大小；\(W_e\) 是 word embedding；\(p_t\) 是每个时间步输出的所有单词的概率分布。</p>

<p>图片 \(I\) 只在 \(t = -1\) 时输入一次，因为论文经过实验后发现如果每个时间步都输入一遍图像，模型会更容易过拟合和学习到图像的噪声。（<a href="https://github.com/ruotianluo/ImageCaptioning.pytorch/blob/master/models/OldModel.py" target="_blank">这里</a>复现了这种做法）</p>

<p>损失函数：</p>

\[L(I,S) = - \sum_{t=1}^N \log p_t (S_t)\]

<p>目标是通过调 CNN、LSTM 和 \(W_e\) 的参数让 Loss 最小。</p>

<p><strong>训练细节</strong>：</p>

<ul>
  <li>用在 ImageNet 上训练好的预训练模型来初始化 CNN 参数，效果提升明显；</li>
  <li>用在一个新闻语料库上训练好的预训练模型来初始化 \(W_e\) 参数，效果提升不明显；</li>
  <li>尝试 dropout 和 ensembling，效果提升了一些；</li>
  <li>调 LSTM hidden units 的数量，最后设成了 512，embedding 维度也设成了 512；</li>
  <li>除了 CNN 以外，其他部分都用 SGD 来调参，随机初始化参数，固定学习率，无 momentum;</li>
  <li>词典中只保留出现次数 &gt; 5 的单词</li>
</ul>

<h5 id="inference">Inference</h5>

<p>在测试生成句子时使用了 beam search，beam size 设为 20。当把 beam size 设为 1（相当于 greedy search）时，BLEU 值降了 2 点左右。</p>

<h4 id="experiments">Experiments</h4>

<p><img src="/img/in-post/2020-03-17/img2txt/img2txt-result.png" alt="result" width="400px" /></p>

<h3 id="show-attend-and-tell">Show, Attend and Tell</h3>

<p><strong>Show, Attend and Tell: Neural Image Caption Generation with Visual Attention.</strong> <em>Kelvin Xu, et al.</em> ICML 2015. <a href="http://proceedings.mlr.press/v37/xuc15.pdf" target="_blank">[Paper]</a> <a href="https://github.com/kelvinxu/arctic-captions" target="_blank">[Code]</a></p>

<p>由于原版代码是用（我不会的）Theano 写的，所以这里是俩用（我大概会的）PyTorch 写的复现代码：</p>

<ul>
  <li>
    <p><a href="https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning" target="_blank">sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning</a></p>

    <p>这个代码写得是真的好…</p>
  </li>
  <li>
    <p><a href="https://github.com/ruotianluo/ImageCaptioning.pytorch" target="_blank">ruotianluo/ImageCaptioning.pytorch</a></p>

    <p>实现了很多模型，作者还有一个名为 <a href="https://github.com/ruotianluo/self-critical.pytorch" target="_blank">self-critical.pytorch</a> 的加强版 repo…</p>
  </li>
</ul>

<p>首次把 Attention 机制用进 Image Captioning 中。</p>

<p>在上述 Encoder-Decoder 结构中，Encoder 和 Decoder 之间唯一的联系只有一个固定长度的语义向量 \(x_{-1}\)，所以 Encoder 必须把原始输入的所有信息都压进 \(x_{-1}\) 中。如果原始输入包含的信息较多， \(x_{-1}\) 可能就无法表达所有信息。而且 \(x_{-1}\) 携带的信息还可能被后面输入的信息覆盖掉。</p>

<p>于是就有了 Attention 机制，最先把它用在 seq2seq 结构中的论文是这篇做机器翻译的：</p>

<p><strong>Neural Machine Translation by Jointly Learning to Align and Translate.</strong> <em>Dzmitry Bahdanau, KyungHyun Cho, and Yoshua Bengio.</em> arXiv 2014. <a href="https://arxiv.org/pdf/1409.0473.pdf" target="_blank">[arXiv]</a></p>

<h4 id="cnn">CNN</h4>

<p>CNN 用了 VGGNet。</p>

<p>前面的论文是用全连接层输出的一个固定长度的向量当特征（高层特征），而这篇论文用了最后一个卷积层（用 Keras 的话说是 block5_conv3）的 \(H \times W \times D\)（\(14 \times 14 \times 512\)）的特征图来当特征（低层特征）：</p>

\[a = \{ \bold{a}_1, ..., \bold{a}_L \}, \bold{a}_i \in \reals^D\]

<p><img src="/img/in-post/2020-03-17/show-attend-tell/vggnet-arrow.png" alt="VGGNet" width="500px" /></p>

<p class="desc">VGGNet 结构</p>

<p>其中 \(H\) 和 \(W\) 为特征图的高度和宽度，\(D\) 为特征图的维度，\(L = H \times W\)。相当于对于图片的 \(L\) 个位置各提一个特征，每个特征都是一个 \(D\) 维向量（annotation vector）。</p>

<p>于是接下来的 LSTM 就需要在这 \(L\) 个位置的特征里选有用的，这就是 Attention 机制。</p>

<h4 id="lstm--attention">LSTM + Attention</h4>

<p>以下是论文里给的 LSTM 结构图和推导公式：</p>

<ul>
  <li>
    <p>LSTM 结构：</p>

    <p><img src="/img/in-post/2020-03-17/show-attend-tell/attention-lstm.png" alt="LSTM" width="400px" /></p>
  </li>
  <li>
    <p>推导公式：</p>

\[i_t = \sigma (W_i E y_{t-1} + U_i h_{t-1} + Z_i \hat{z}_t + b_i)\]

\[f_t = \sigma (W_f E y_{t-1} + U_f h_{t-1} + Z_f \hat{z}_t + b_f )\]

\[c_t = f_t c_{t-1} + i_t \text{tanh} (W_c E y_{t-1} + U_c h_{t-1} + Z_c \hat{z}_t + b_c)\]

\[o_t = \sigma (W_o E y_{t-1} + U_o h_{t-1} + Z_o \hat{z}_t + b_o)\]

\[h_t = o_t \text{tanh} (c_t)\]
  </li>
</ul>

<p>但从代码实现来看（以原版代码为准），图应该画成这样（代码实现跟论文描述的出入会在后面提到）（图来自论文 <a href="#adaptive-attention">Adaptive Attention</a>）：</p>

<p><img src="/img/in-post/2020-03-17/show-attend-tell/true-attention-lstm.png" alt="True LSTM" width="400px" /></p>

<p><code class="info highlighter-rouge">备注</code> 虽然在图和推导式里，上一步输出 \(y_{t-1}\) 也参与了这一步的计算，但代码（原版和复现）里似乎没有参与。</p>

<p>跟正常 LSTM 的区别是用 context vector \(\hat{z}_t\) 来代替了当前输入 \(x_t\)。</p>

<p><code class="info highlighter-rouge">备注</code> 按论文里的描述是这样，即 \(x_t\) 完全没有参与计算。但代码（原版和复现）里是把 \(\hat{z}_t\) 和 \(x_t\) 拼到了一起作为输入。</p>

<p>\(\hat{z}_t\) 由 \(\phi\) 函数对 \(\{ \bold{a}_1, ..., \bold{a}_L \}\) 进行一些加权得到，\(\alpha_i\) 为 \(\bold{a}_i\) 的权重：</p>

\[\hat{z}_t = \phi(\{\bold{a}_i\}, \{\alpha_i\})\]

<p>Soft Attention 和 Hard Attention 的不同在于 \(\phi\) 的不同。在 <strong>Soft Attention</strong> 中：</p>

\[\hat{z}_t = \phi(\{\bold{a}_i\}, \{\alpha_i\}) = \beta \sum_i^L \alpha_{t,i} \bold{a}_i\]

<p>\(\beta\) 是一个决定当前时间步要用多少 context 信息的门控信号：</p>

\[\beta = \sigma (f_{\beta} (h_{t-1}))\]

<p>相当于在 Soft Attention 中，\(\alpha_{t,i}\) 代表图像的第 \(i\) 个位置的特征 \(\bold{a}_i\) 在 \(t\) 时刻输入 Decoder 的信息所占的比例，即对 \(\bold{a}_i\) 求加权平均。\(\alpha_{t,i}\) 由 Attention 模型 \(f_{att}\)（也就是一个 MLP）计算得到：</p>

\[e_{ti} = f_{att}(\bold{a}_i, h_{t-1})\]

<p>然后把 \(e_{ti}\) 归一化（softmax）后就得到了 \(\alpha_{ti}\)：</p>

\[\alpha_{ti} = \frac{\exp(e_{ti})}{\sum_{k=1}^L \exp(e_{tk})}\]

<p>除了标准化自带的 \(\sum_i^L \alpha_{ti} = 1\) 这个限定以外，还对 \(\alpha_{ti}\) 加了另一个限定，来避免图像某些部分的特征被忽略（论文里设的 \(\tau = 1\)）：</p>

\[\sum_t \alpha_{ti} \approx \tau, \tau \geq \frac{L}{D}\]

<p>所以 Soft Attention 模型的训练目标是要最小化以下惩罚函数：</p>

\[L_d = - \log(p(y \mid \bold{a})) + \lambda \sum_i^L (1 - \sum_t^C \alpha_{ti})^2\]

<p>细胞状态和隐状态初始值为（\(f_{init, c}\) 和 \(f_{init, h}\) 都是 MLP）：</p>

\[c_0 = f_{init, c} (\frac{1}{L} \sum_i^L \bold{a}_i)\]

\[h_0 = f_{init, h} (\frac{1}{L} \sum_i^L \bold{a}_i)\]

<p>最终输出的单词概率分布为：</p>

\[p(y_t \mid \bold{a}, y_{t-1}) \propto  \exp (L_o (Ey_{t-1} + L_h h_t + L_z \hat{z}_t))\]

<p>其中，\(L_o\)、\(L_h\)、\(L_z\)、\(E\) 都是需要学习的权重参数。</p>

<p><code class="info highlighter-rouge">备注</code> 似乎只有原版代码算是按照上面这个公式来算的单词概率（而且它依然没有考虑 \(y_{t-1}\)），俩复现代码都直接把 \(h_t\) 扔进 softmax 完事，即：\(y_t = \text{softmax}(h_t)\)。</p>

<h4 id="experiments-1">Experiments</h4>

<p><img src="/img/in-post/2020-03-17/show-attend-tell/attention-result.png" alt="Result" /></p>

<h3 id="adaptive-attention">Adaptive Attention</h3>

<p><strong>Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning.</strong> <em>Jiasen Lu, et al.</em> CVPR 2017. <a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Lu_Knowing_When_to_CVPR_2017_paper.pdf" target="_blank">[Paper]</a> <a href="https://github.com/jiasenlu/AdaptiveAttention" target="_blank">[Code]</a></p>

<p>不是每个单词的生成都需要利用图像特征，有的词的生成只需要依赖语义信息，如“the”、“of”等词，和跟在“talking on a cell”后面的“phone”等词。因此该论文的 Adaptive Attention 机制能决定当前时间步要用多少图像特征和多少语义信息。</p>

<h4 id="cnn-1">CNN</h4>

<p>用了 ResNet，最后一个卷积层输出 \(2048 \times 7 \times 7\) 的特征图，表示为：</p>

\[A = \{ a_1, ..., a_k \}, a_i \in R^{2048}\]

<p>对每个向量做以下变换：</p>

\[v_i = \text{ReLU}(W_a a_i)\]

<p>则最终的图像特征为：</p>

\[V = [v_1, ... , v_k]\]

<p>论文还算了一个全局图像特征，即把特征图中所有向量做个算术平均，然后做个类似的变换：</p>

\[a^g = \frac{1}{k} \sum_{i=1}^k a_i\]

\[v^g = \text{ReLU} (W_b a^g)\]

<p>然后 LSTM 每个时间步的输入为把 word embedding 和 \(v^g\) 拼到一起后的结果，即：</p>

\[x_t = [w_t; v^g]\]

<h4 id="spatial-attention">Spatial Attention</h4>

<p>首先对 Attention 机制做了一些修改：</p>

<p><img src="/img/in-post/2020-03-17/adaptive-attention/spatial-attention.png" alt="Spatial Attention" width="500px" /></p>

<p class="desc">(a)：Show, Attend and Tell 网络结构，(b)：该论文的 Spatial Attention 网络结构</p>

<p>与<a href="#show-attend-and-tell">上一篇论文</a>的不同：</p>

<ul>
  <li>
    <p>计算 context vector \(c_t\) 时用了 \(h_t\) 而不是 \(h_{t-1}\)，论文认为这样 \(c_t\) 就可以看作 \(h_t\) 的残差连接，可以在生成下一个词时降低不确定性和提供当前时刻隐状态的信息，灵感来源于 <a href="http://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf" target="_blank">ResNet</a></p>
  </li>
  <li>
    <p>\(c_t\) 没有输入 LSTM</p>
  </li>
</ul>

<p>context vector \(c_t\) 定义为：</p>

\[c_t = g(V, h_t)\]

<p>\(V = [v_1, ... , v_k] , v_i \in R^d\) 是<a href="#cnn-1">上一步</a>中操作出来的图像特征，\(g\) 是 Attention 模型。</p>

<p>\(g\) 的具体实现如下，先算权重 \(\alpha_t\)（MLP + softmax）：</p>

\[z_t = w^T_h \text{tanh}(W_v V + (W_g h_t) \frak{1}^T) \tag{1}\]

\[\alpha_t = \text{softmax}(z_t)\]

<p>\(\frak{1} \in R^k\) 是一个元素全为 1 的向量，目的是跟 \(W_g h_t\) 相乘得到 \(k \times k\) 的矩阵。\(W_v, W_g \in R^{k \times d}\)
和 \(w_h \in R^k\) 都是要学习的权重参数。</p>

<p>然后对 \(V\) 加权平均，得到 \(c_t\)：</p>

\[c_t = \sum_{i=1}^k \alpha_{ti} v_{ti}\]

<h4 id="adaptive-attention-1">Adaptive Attention</h4>

<p><img src="/img/in-post/2020-03-17/adaptive-attention/adaptive-attention.png" alt="Adaptive Attention" width="400px" /></p>

<p>在 LSTM 上新增了一个叫 visual sentinel 的向量 \(s_t\)，用于记录一部分的细胞状态：</p>

\[g_t = \sigma (W_x x_t + W_h h_{t-1})\]

\[s_t = g_t \odot \text{tanh} (m_t)\]

<p>\(g_t\) 是个门控信号，\(m_t\) 是 \(t\) 时刻的细胞状态，\(\sigma\) 是 sigmoid 激活函数。跟 <a href="/2019/02/15/rnn-with-its-friends/#输出门" target="_blank">LSTM 输出门</a>公式的形式是一样的，但是分别由不同的权重控制。</p>

<p>于是 Adaptive Attention 中的 context vector \(\hat{c}_t\) 为：</p>

\[\hat{c}_t = \beta_t s_t + (1 - \beta_t) c_t\]

<p>\(\beta_t \in [0,1]\) 是一个控制 \(t\) 时刻要利用多少 \(s_t\)（语义信息）和 \(c_t\)（图像特征）的门控信号（sentinel gate）。为了算出 \(\beta_t\)，把 Attention 权重的计算公式也做了修改，新的权重 \(\hat{\alpha}\) 为：</p>

\[\hat{\alpha}_t = \text{softmax}([z_t; w^T_h \text{tanh}(W_s s_t + (W_g h_t))])\]

<p>相当于把 \(z_t\) 跟 \(w^T_h \text{tanh}(W_s s_t + (W_g h_t))\) 拼了起来。这里的 \(W_g\) 跟公式 \((1)\) 中的 \(W_g\) 是一样的，同时虽然论文中没说，但 \(w^T_h\) 的确也是一样的。</p>

<p>\(\hat{\alpha}_t\) 有 \(k+1\) 个元素，则 \(\beta_t\) 为：</p>

\[\beta_t = \hat{\alpha}_t[k+1]\]

<p>单词概率分布为：</p>

\[p_t = \text{softmax} (W_p (\hat{c}_t + h_t))\]

<h4 id="experiments-2">Experiments</h4>

<p><img src="/img/in-post/2020-03-17/adaptive-attention/adaptive-attention-result.png" alt="result" /></p>

<h3 id="self-critical">Self-critical</h3>

<p><strong>Self-critical Sequence Training for Image Captioning.</strong> <em>Steven J. Rennie, et al.</em> CVPR 2017. <a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Rennie_Self-Critical_Sequence_Training_CVPR_2017_paper.pdf" target="_blank">[Paper]</a></p>

<p>Pytorch 复现：<a href="https://github.com/ruotianluo/self-critical.pytorch" target="_blank">ruotianluo/self-critical.pytorch</a></p>

<p>之前的方法都是用最大似然进行语言建模，在训练时最大化模型生成的单词序列的联合概率，从而最小化交叉熵损失。这种方法存在两个问题：</p>

<ul>
  <li>
    <p>曝光偏差（exposure bias）：训练时用了 teacher forcing，即解码器每个时刻的输入都是训练集中的真实单词（ground truth），而测试时，解码器每个时刻的输入是自己上一时刻生成的单词，如果某一个单词预测得不够准确，之后所有单词的预测都会受到影响；</p>
  </li>
  <li>
    <p>训练目标和评价准则不匹配：训练时用的交叉熵损失函数，而验证时用的是 BLEU、ROUGE、METEOR、CIDEr 之类的指标，导致模型训练时无法做到充分的优化评估指标。</p>
  </li>
</ul>

<p>于是一个自然的想法是直接优化评估指标（CIDEr）。但由于生成单词的操作不可微，所以不能用一般的反向传播梯度下降来优化这些指标，因此考虑用强化学习（中的 Policy Gradient 方法）来优化。</p>

<h4 id="policy-gradient">Policy Gradient</h4>

<p>如果把图像描述问题看成强化学习问题：</p>

<ul>
  <li>agent：decoder</li>
  <li>environment：单词和图像特征</li>
  <li>policy：\(p_{\theta}\)，由模型参数 \(\theta\) 决定</li>
  <li>action：对下一个单词的预测</li>
  <li>state：decoder 要更新的各种状态，如 LSTM 隐状态和细胞状态、 attention 权重等</li>
  <li>reward：\(r\)，CIDEr 值</li>
</ul>

<p>训练目标是最大化期望 reward，因为要用梯度下降，所以写成最小化负期望 reward：</p>

\[L(\theta) = - \mathbb{E}_{w^s \thicksim p_{\theta}} [r(w^s)] = - \sum_{w^s} p_{\theta}(w^s) r(w^s)\]

<p>其中，\(w^s = (w_1^s, ... , w_T^s)\) 是生成的句子，\(r(w^s)\) 是 \(w^s\) 上的 \(\gamma\) 折扣累积 reward：</p>

\[r(w^s) = r_1 + \gamma r_2 + \gamma_1 r_3 + ... +  \gamma_{T-1} r_T\]

<p>对 \(L(\theta)\) 求梯度：</p>

\[\begin{aligned}
  \nabla_{\theta} L(\theta) = - \nabla_{\theta} \mathbb{E}_{w^s \thicksim p_{\theta}} [r(w^s)] &amp;= - \nabla_{\theta} \sum_{w^s} p_{\theta}(w^s) r(w^s) \\
  &amp;= - \sum_{w^s} \nabla_{\theta}  p_{\theta}(w^s) r(w^s) \\
  &amp;= - \sum_{w^s} p_{\theta}(w^s) \frac{\nabla_{\theta} p_{\theta}(w^s)}{p_{\theta}(w^s)} r(w^s)\\
  &amp;= - \sum_{w^s} p_{\theta}(w^s) \nabla_{\theta} \log p_{\theta}(w^s) r(w^s)\\
  &amp;= - \mathbb{E}_{w^s \thicksim p_{\theta}} [r(w^s) \nabla_{\theta} \log p_{\theta}(w^s)]
\end{aligned}\]

<p>推导过程参考：<a href="http://karpathy.github.io/2016/05/31/rl/" target="_blank">Deep Reinforcement Learning: Pong from Pixels</a></p>

<p>实际训练时，会用蒙特卡洛的思想从 \(p_{\theta}\) 中按概率随机采样出一个单词序列 \(w^s = (w_1^s, ... , w_T^s)\) 来估计出梯度的近似值：</p>

\[\nabla_{\theta} L(\theta) \approx -r(w^s) \nabla_{\theta} \log p_{\theta} (w^s)\]

<p>因为采样的每一步都具有较大的随机性，可能会使最终得到的样本之间差异巨大，所以一般认为这种基于蒙特卡洛采样的近似方法会导致估计出的梯度有较高的方差。于是为了引入了一个 baseline \(b\) 来减小方差，即：</p>

\[\nabla_{\theta} L(\theta) = - \mathbb{E}_{w^s \thicksim p_{\theta}} [(r(w^s) - b) \nabla_{\theta} \log p_{\theta}(w^s)]\]

<p>只要 \(b\) 不依赖于 \(w^s\)，减去一个 \(b\) 并不会改变梯度的值，证明过程为：</p>

\[\begin{aligned}
  \mathbb{E}_{w^s \thicksim p_{\theta}} [b \nabla_{\theta} \log p_{\theta}(w^s)] &amp;= b \sum_{w_s} \nabla_{\theta} p_{\theta}(w^s) \\
  &amp;= b \nabla_{\theta} \sum_{w_s}  p_{\theta}(w^s) \\
  &amp;= b \nabla_{\theta} 1 = 0
\end{aligned}\]

<p>所以估计出的梯度为：</p>

\[\nabla_{\theta} L(\theta) \approx -(r(w^s) - b) \nabla_{\theta} \log p_{\theta} (w^s)\]

<p>由链式法则可以得到：</p>

\[\nabla_{\theta} L(\theta) = \sum_{t=1}^T \frac{\partial L(\theta)}{\partial s_t} \frac{\partial s_t}{\partial \theta}\]

<p>其中 \(s_t\) 是 softmax 的输入，是一个长度为词典大小的向量，表示了 \(t\) 时刻词典中每个单词的分数。</p>

<p>把 \(\frac{\partial L(\theta)}{\partial s_t}\) 近似一下可以得到：</p>

\[\frac{\partial L(\theta)}{\partial s_t} \approx (r(w^s)-b)(p_{\theta}(w_t \mid h_t) - 1_{w_t^s}) \tag{2}\]

<p>其中 \(1_{w_t^s}\) 是单词 \(w_t^s\) 的独热编码向量。这个近似相当于把 \(w_t^s\) 当成了 \(t\) 时刻 \(p_{\theta}(w_t \mid h_t)\) 的目标输出，在 <a href="https://arxiv.org/pdf/1511.06732.pdf" target="_blank">MIXER 的论文</a>里有解释。</p>

<p>因为公式 \((2)\) 的第二项 \((p_{\theta}(w_t \mid h_t) - 1_{w_t^s})\) 一定小于 0，所以当样本的 reward 大于 baseline \(b\) 时，梯度为负，梯度下降时就会提高单词 \(w_t^s\) 的分数，否则就会抑制 \(w_t^s\) 的分数。一般来说会用对当前模型的 reward 的平均值的估计函数作为 baseline，如在 MIXER 中，baseline \(\bar{r}_t\) 是一个线性回归模型，通过优化均方误差 \(\lVert \bar{r}_t - r \rVert^2\) 得到。</p>

<h4 id="scst">SCST</h4>

<p><strong>self-critical sequence training</strong></p>

<p>论文把 baseline 定义为当前模型通过 greedy decoding 得到的句子 \(\hat{w}\) 的reward。所以叫 self-critical，因为 baseline 也是自己生成的，相当于自己跟自己比。于是有：</p>

\[\frac{\partial L(\theta)}{\partial s_t} \approx (r(w^s) - r(\hat{w}))(p_{\theta}(w_t \mid h_t) - 1_{w_t^s})\]

<p><img src="/img/in-post/2020-03-17/self-critical/self-critical.png" alt="self-critical" /></p>

<p>论文认为这样做的优点是：</p>

<ul>
  <li>不用另外训练一个模型来当 baseline，只需要用现有模型 inference 一遍，降低了训练复杂度</li>
  <li>训练和测试阶段的一致性，都用的同样的生成方法（但训练时不是随机采样吗…）</li>
  <li>梯度方差低于 MIXER，训练得更快（用 SGD 时）</li>
</ul>

<p>用强化学习的方法训练之前，会先用交叉熵损失进行预训练。</p>

<h4 id="experiments-3">Experiments</h4>

<ul>
  <li>
    <p>与以优化交叉熵损失（XE）为目标的模型和用 MIXER 方法训练的模型的对比实验：</p>

    <p><img src="/img/in-post/2020-03-17/self-critical/sc-result1.png" alt="self-critical result1" width="400px" /></p>
  </li>
  <li>
    <p>尝试 curriculum learning，即先对最后一个单词以优化 CIDEr 为目标进行训练，前面的词则以优化交叉熵损失为目标进行训练，然后每个 epoch 增加一个用 CIDEr 进行训练的单词。但这种方法至少在 MSCOCO 上对效果没有提升。</p>
  </li>
  <li>
    <p>尝试以优化别的指标为目标，但优化 CIDEr 的效果是最好的，能把所有指标都往上拉：</p>

    <p><img src="/img/in-post/2020-03-17/self-critical/sc-result2.png" alt="self-critical result2" width="450px" /></p>
  </li>
  <li>
    <p>发现 beam search 对 RL 训练出来的模型效果提升很小：</p>

    <p><img src="/img/in-post/2020-03-17/self-critical/sc-result3.png" alt="self-critical result3" width="450px" /></p>

    <p>作为对比，这是 beam search 对用交叉熵损失训练出来的模型效果提升：</p>

    <p><img src="/img/in-post/2020-03-17/self-critical/sc-result4.png" alt="self-critical result4" width="450px" /></p>
  </li>
  <li>
    <p>似乎能对 objects out-of-context (OOOC) 的图片生成比较好的结果</p>
  </li>
</ul>

<h2 id="image-aesthetic-captioning">Image Aesthetic Captioning</h2>

<h3 id="aesthetic-critiques">Aesthetic Critiques</h3>

<p><strong>Aesthetic Critiques Generation for Photos.</strong> <em>Kuang-Yu Chang, Kung-Hung Lu, and Chu-Song Chen.</em> ICCV 2017. <a href="https://ieeexplore.ieee.org/document/8237642" target="_blank">[IEEE]</a> <a href="https://www.iis.sinica.edu.tw/~kuangyu/iccv17_aesthetic_critiques.pdf" target="_blank">[Paper]</a> <a href="https://github.com/kunghunglu/DeepPhotoCritic-ICCV17" target="_blank">[Code]</a> <a href="https://github.com/ivclab/DeepPhotoCritic-ICCV17" target="_blank">[Dataset]</a></p>

<p>开图像美感描述这个坑的第一篇论文，数据集 PCCD 的提出者（虽然我并没有找到这个数据集）。该论文考虑从不同美学角度来对图片进行美感描述，对每个角度而言大概就跟 Image Captioning 差不多了。</p>

<p>训练数据结构：</p>

\[D = (\Phi_i, C_i, a_i), i \in \{ 1 ... N \}\]

<p>\(\Phi_i\) 是第 \(i\) 张图片，\(C_i\) 是它的描述（同一张图片可能有多个不同角度的描述），\(a_i\)（\(i \in \{1 ... L\}\)）是该描述的角度。在此之外，还有一个 \(p_{i,l} \in [0, 1]\) 来描述图片 \(\Phi_i\) 在角度 \(l\) 上的美感分数。</p>

<h4 id="aspect-oriented">Aspect-oriented</h4>

<p><strong>Baseline - Aspect-oriented (AO) Approach</strong></p>

<p>AO 中，训练数据中每张图都只带有一个角度的描述，即 \((\Phi_i, C_i, l)\)。然后用 CNN-LSTM 在每个角度的数据上进行训练。</p>

<p>相当于要对 \(L\) 个角度各建一个 CNN-LSTM 模型。关于 CNN-LSTM 可以参考 <a href="#show-and-tell">Show and Tell</a> 那篇论文。</p>

<p>CNN 还会用 \(\{ (\Phi_i; p_{i,l}) \}\) 进行训练。在测试时，它会输出图片在每个角度上的美感分数，然后把得分最高的角度 \(l^*\) 所对应的 CNN-LSTM 模型的输出结果当做最终结果。流程图如下：</p>

<p><img src="/img/in-post/2020-03-17/pccd/ao.png" alt="ao-approach" width="400px" /></p>

<h4 id="aspect-fusion">Aspect-fusion</h4>

<p>AO 只能输出一个角度的描述，比较单一。为了解决这个问题，论文先尝试把整个数据集都扔进 CNN-LSTM 训练，但效果不好。</p>

<p><strong>Aspect-fusion (AF) Approach</strong></p>

<p>于是论文决定在测试时把 AO 中每个角度的 CNN-LSTM 模型输出的隐状态 \(h_l = \{ h_{l,t} \mid t = 1 ... T, l = 1 ... L \}\) 用 Soft Attention 融合一下之后，当做输入扔进一个新的 LSTM 中，于是新的 LSTM 的递推公式为：</p>

\[(g_{\tau}, y_{\tau} ) = F(g_{\tau-1}, x_{\tau}, s_{\tau} )\]

<p>\(y_{\tau}\) 为概率分布，\(x_{\tau}\) 为当前输入，\(g_{\tau - 1}\) 为上一时刻的隐状态，\(s_{\tau}\) 为 Soft Attention 融合出来的 context vector。</p>

<p><strong>Soft Attention</strong></p>

<p>\(s_{\tau}\) 相当于是对 \(h_{lt}\) 求加权平均：</p>

\[s_{\tau} = \sum_{l=1}^{L} \sum_{t=1}^{T} \alpha_{lt}^{\tau} (h, g_{\tau-1}) h_{lt}\]

<p>其中，权重 \(\alpha_{lt}^{\tau}\) 需要在 Soft Attention 模型中生成：</p>

\[e_{lt}^{\tau} = A(g_{\tau-1}, h_{lt}) = W_{\gamma} (Ug_{\tau-1} + Vh_{lt})\]

\[\alpha_{lt}^{\tau} = \frac{ \exp (e_{lt}^{\tau}) }{ \sum_{p=1}^L \sum_{q=1}^T \exp (e_{pq}^{\tau}) }\]

<p>其中，\(\gamma\) 是 ReLU 激活函数，\(W \in R^{n \times n}\)、\(U \in R^{n \times n}\) 和 \(V \in R^{n \times n}\) 是需要学习的权重，\(n\) 是 LSTM 隐藏层大小（论文里面设的 768）。</p>

<p>流程图如下（自行加了一些不知对不对的标注）：</p>

<p><img src="/img/in-post/2020-03-17/pccd/af.jpg" alt="af-approach" width="600px" /></p>

<p>相当于论文认为 CNN-LSTM 输出的隐状态可以被看做每个角度的输入的深层特征，然后 Soft Attention 机制又可以很好的把它们融合到一起。</p>

<p><strong>困惑：</strong>按照代码里面的写法，第二个 LSTM 明明已经是在生成融合各个角度之后的句子了，却依然把每个角度的句子分别输入和用来算损失，感觉说不通，虽然的确也没有角度融合后的 ground truth 就是了…</p>

<h4 id="pccd">PCCD</h4>

<p>图片和评论来源于 <a href="https://gurushots.com/" target="_blank">GuruShots</a>，评论被分为了 7 个角度，每个角度都有评分（评分范围为 1-10）：</p>

<p><img src="/img/in-post/2020-03-17/pccd/pccd.png" alt="PCCD" width="450px" /></p>

<h4 id="experiments-4">Experiments</h4>

<p>因为不是每个角度都有评论，所以实验时论文只选了 3 个角度（composition and perspective、color and lighting、subject of photo）。为了控制词典大小，词典中只保留出现次数 &gt; 5 的单词，其他单词会被映射为 <code class="highlighter-rouge">&lt;UNK&gt;</code>。</p>

<p>论文直接用了 <a href="#show-and-tell">NeuralTalk2</a> 来当 CNN-LSTM 模型，拿了在 MSCOCO 数据集上预训练好的模型在 PCCD 上 fine-tune（只 fine-tune 了 LSTM 部分，CNN 部分保持不变）。</p>

<p>评估指标用了 <a href="https://panderson.me/images/SPICE.pdf" target="_blank">SPICE</a>。</p>

<p>实验结果：</p>

<p><img src="/img/in-post/2020-03-17/pccd/pccd-result.png" alt="result" width="450px" /></p>


                <hr style="visibility: hidden;">
                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2020/02/29/image-aesthetic-assessment/" data-toggle="tooltip" data-placement="top" title="图像美感评估">
                        Previous<br>
                        <span>图像美感评估</span>
                        </a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/2020/07/10/messy-notes-nlp/" data-toggle="tooltip" data-placement="top" title="乱七八糟的知识点">
                        Next<br>
                        <span>乱七八糟的知识点</span>
                        </a>
                    </li>
                    
                </ul>
                <hr style="visibility: hidden;">
                
                <section class="author-profile">
    <div class="info"> 
        <div class="avatar">
            <img src="/img/header-avatar.jpeg">
        </div>
        <h1>Renovamen</h1>
    </div>
    <span>
        <a href="https://www.jinrishici.com/" target="_blank">
            <i class="fas fa-pencil-alt"></i>
        </a>
        <p id="poem-item">作诗中...</p>
        <br><p id="poem-info"></p>
    </span>
</section>
                
                
                    <!-- Comment container -->

<!-- disqus -->

<div class="comment">
    <div id="gitalk-container"></div>
</div>

<!-- Valine -->

                
            </div>  

            <!-- Side Catalog Container -->
            
                <!-- Side Catalog Container -->
<div class="
    col-lg-2 col-lg-offset-0
    sidebar-container
    catalog-container">
    <div class="side-catalog">
        <hr class="hidden-sm hidden-xs">
        <h5>
            <a class="catalog-toggle" href="#">CATALOG</a>
        </h5>
        <ul class="catalog-body"></ul>
    </div>
</div>
            
        </div>
    </div>
</article>

<!-- add support for mathjax by voleking-->

    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css">
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"></script>

<script>
    $("script[type='math/tex']").replaceWith(function() {
        var tex = $(this).text();
        return katex.renderToString(tex, {displayMode: false});
    });
  
    $("script[type='math/tex; mode=display']").replaceWith(function() {
        var tex = $(this).html();
        return katex.renderToString(tex.replace(/%.*/g, ''), {displayMode: true});
    });
</script>
    


<!-- Renovamen: add support for chart and mermaid -->

    <!-- Borrowed from: https://github.com/kitian616/jekyll-TeXt-theme -->
<!-- Chart.js: https://www.chartjs.org/docs/latest/ -->
<script>
    LazyLoad.js("https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js", function(){
        var $canvas = null, $this = null, _ctx = null, _text = '';
        $('.language-chart').each(function(){
            $this = $(this);
            $canvas = $('<canvas></canvas>');
            _text = $this.text();
            $this.text('').append($canvas);
            _ctx = $canvas.get(0).getContext('2d');
            (_ctx && _text) && (new Chart(_ctx, JSON.parse(_text)) && $this.attr('data-processed', true));
        });
    })

    $('.language-chart').parent().css({
        "background-color": "transparent",
        "border": "none",
    });
</script>





    <!-- Borrowed from: https://github.com/kitian616/jekyll-TeXt-theme -->
<!-- mermaid.js: https://mermaid-js.github.io/mermaid/ -->
<script>
    LazyLoad.js('https://cdn.jsdelivr.net/npm/mermaid@8.4.8/dist/mermaid.min.js', function() {
        mermaid.initialize({
            startOnLoad: true
        });
        mermaid.init(undefined, '.language-mermaid');
    });

    $('.language-mermaid').parent().css({
        "background-color": "transparent",
        "border": "none",
    });
</script>


<!-- Renovamen: add support for additional emoji -->

    <script>
$('.emoji-plus').each(function(){
    var $this = $(this);
    var imgURL = '/img/emoji/bilitv/' + $this.text() + '.gif';
    var $img = $('<img class="emoji-plus" src="' + imgURL + '" height="30" width="30">');
    $this.replaceWith($img);
});
</script>


<!-- comment -->

    <!-- Gitalk start -->
<script type="text/javascript">
    LazyLoad.js(['/js/library/md5.js ', 'https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js'], function(){
        var gitalk = new Gitalk({
            clientID: 'd6247712dc288a5a60ca',
            clientSecret: 'ed1ec72417828343c79ed910a1b77d140fa715a7',
            repo: 'gitalk-comments',
            owner: 'This-is-an-Apple',
            admin: ['Renovamen', 'This-is-an-Apple'],
            id: md5(location.pathname),
            distractionFreeMode: false
        });
        gitalk.render('gitalk-container');
    })
</script>
<!-- Gitalk end -->






    <!-- anchor.js: http://bryanbraun.github.io/anchorjs/ -->
<script>
    LazyLoad.js("https://cdn.jsdelivr.net/npm/anchor-js@4.2.2/anchor.min.js", function(){
        anchors.options = {
          visible: 'always',
          placement: 'right',
          icon: '#'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>


<!-- Renovamen: add support 今日诗词: https://www.jinrishici.com/ -->
<script type="text/javascript">
    LazyLoad.js(['https://sdk.jinrishici.com/v2/browser/jinrishici.js'], function(){
        jinrishici.load(function(result) {
            var poem = document.querySelector('#poem-item');
            var info = document.querySelector('#poem-info');

            if (result.status === "success") {
                var data = result.data
                console.log(data)
                poem.innerHTML = data.content;
                info.innerHTML = '【' + data.origin.dynasty + '】' + data.origin.author + '《' + data.origin.title + '》';
            }
        });
    })
</script>

    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <!-- SNS Link -->
                <!-- 


<div class="list-inline text-center">

  
  <a target="_blank" href="https://github.com/Renovamen">
    <span class="fa-stack fa-lg">
      <i class="fas fa-circle fa-stack-2x"></i>
      <i class="fab fa-github-alt fa-stack-1x fa-inverse"></i>
    </span>
  </a>
  
  
  <a target="_blank" href="https://www.linkedin.com/in/xiaohan-zou-55bba0160">
    <span class="fa-stack fa-lg">
      <i class="fas fa-circle fa-stack-2x"></i>
      <i class="fab fa-linkedin-in fa-stack-1x fa-inverse"></i>
    </span>
  </a>
  
  
  <a target="_blank" href="https://www.facebook.com/renovamen.zou">
    <span class="fa-stack fa-lg">
      <i class="fas fa-circle fa-stack-2x"></i>
      <i class="fab fa-facebook-f fa-stack-1x fa-inverse"></i>
    </span>
  </a>
  
  
  <a target="_blank" href="https://twitter.com/renovamen_zxh">
    <span class="fa-stack fa-lg">
      <i class="fas fa-circle fa-stack-2x"></i>
      <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
    </span>
  </a>
  
  
  <a target="_blank" href="https://www.zhihu.com/people/chao-neng-gui-su">
    <span class="fa-stack fa-lg">
      <i class="fas fa-circle fa-stack-2x"></i>
      <i class="fas fa-stack-1x fa-inverse">知</i>
    </span>
  </a>
  
  
  
  <a href="mailto:renovamenzxh@gmail.com">
    <span class="fa-stack fa-lg">
      <i class="fas fa-circle fa-stack-2x"></i>
      <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
    </span>
  </a>
  
  
  <a target="_blank" href="/feed.xml">
    <span class="fa-stack fa-lg">
      <i class="fas fa-circle fa-stack-2x"></i>
      <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
    </span>
  </a>
  
</div> -->
                <p class="copyright">
                    &copy; <a href="https://github.com/Renovamen" target="_blank">Renovamen</a> 2018
                    <br>
                    Powered by <a href="https://jekyllrb.com/" target="_blank">Jekyll</a> & <a href="https://github.com/Renovamen/renovamen.github.io" target="_blank">Gungnir</a>
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<!-- Renovamen: has been included in `head.html` already -->
<!-- <script src="https://cdn.jsdelivr.net/npm/jquery@2.1.3/dist/jquery.min.js"></script> -->

<!-- Bootstrap Core JavaScript -->
<!-- Currently, only navbar scroll-down effect at desktop still depends on this -->
<!-- Renovamen: Maybe don't need this anymore -->
<!-- <script src="/js/library/bootstrap.min.js "></script> -->

<!-- add dark / light detection -->
<!-- dark / light detection, borrowed from gridsome.org -->
<script>
  (function() {
    window.__onThemeChange = function() {};
    function setTheme(newTheme) {
      window.__theme = newTheme;
      preferredTheme = newTheme;
      document.body.setAttribute('data-theme', newTheme);
      window.__onThemeChange(newTheme);
      setThemeIcon(newTheme)
    }

    var preferredTheme;
    try {
      preferredTheme = localStorage.getItem('theme');
    } catch (err) { }

    window.__setPreferredTheme = function(newTheme) {
      setTheme(newTheme);
      try {
        localStorage.setItem('theme', newTheme);
      } catch (err) {}
    }

    var darkQuery = window.matchMedia('(prefers-color-scheme: dark)');

    darkQuery.addListener(function(e) {
      window.__setPreferredTheme(e.matches ? 'dark' : 'light');
    });

    setTheme(preferredTheme || (darkQuery.matches ? 'dark' : 'light'));
  })();
</script>

<!-- Theme JavaScript -->
<script src="/js/gungnir.min.js"></script>

<!-- Service Worker -->

<script src="/js/snackbar.js"></script>
<script src="/js/sw-registration.js"></script>



<!--
     Because of the native support for backtick-style fenced code blocks
     right within the Markdown is landed in Github Pages,
     From V1.6, There is no need for Highlight.js,
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/
     - https://github.com/jneen/rouge/wiki/list-of-supported-languages-and-lexers
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->


<!--fastClick.js -->
<script>
    LazyLoad.js("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->

    <!-- Google Analytics -->
<script>
    // dynamic User by Hux
    var _gaId = 'UA-146858305-1';
    var _gaDomain = 'renovamen.ink';

    // Originial
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', _gaId, _gaDomain);
    ga('send', 'pageview');
</script>



<!-- Baidu Tongji -->

    <!-- Baidu Tongji -->
<script>
    // dynamic User by Hux
    var _baId = '75381d210789d3eaf855fa16246860cc';

    // Originial
    var _hmt = _hmt || [];
    (function() {
        var hm = document.createElement("script");
        hm.src = "//hm.baidu.com/hm.js?" + _baId;
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>



<!-- Side Catalog -->

    <!-- tocbot: https://github.com/tscanlin/tocbot -->

<!-- 
    Didn't use lazyload here because it will cause some bugs in catalog 
    generating when swtiching between two languages. 
    I'm trying to find a better solution.
-->

<link href="https://cdn.jsdelivr.net/npm/tocbot@4.10.0/dist/tocbot.css" rel="stylesheet" type="text/css">
<script src="https://cdn.jsdelivr.net/npm/tocbot@4.10.0/dist/tocbot.min.js"></script>

<script type="text/javascript">
    function generateCatalog(selector) {

        // links page
        if('post' == 'links') {
            _containerSelector = 'div.link-list'
        }
        // interop with multilangual 
        else {
            if ('' == 'true') {
                _containerSelector = 'div.post-container.active'
            } 
            else {
                _containerSelector = 'div.post-container'
            }
        }
        
        tocbot.init({
            // Where to render the table of contents.
            tocSelector: selector,
            // Where to grab the headings to build the table of contents.
            contentSelector: _containerSelector,
            // Which headings to grab inside of the contentSelector element.
            headingSelector: 'h2, h3, h4, h5, h6',
        });
        return true;
    }

    generateCatalog(".catalog-body");

    // toggle side catalog
    $(".catalog-toggle").click((function(e){
        e.preventDefault();
        $('.side-catalog').toggleClass("fold")
    }))
</script>



<!-- Multi-Lingual -->

    </div>

    <!-- modify styles of navbar on mobile -->
    <div class="mobile-nav">
    <div class="mobile-menu-avatar">
        <div class="avatar-container">
            <img src="/img/header-avatar.jpeg">
        </div>
    </div>
    <p class="mobile-menu-heading">Meow?</p>
    


<div class="list-inline text-center">

  
  <a target="_blank" href="https://github.com/Renovamen">
    <span class="fa-stack fa-lg">
      <i class="fas fa-circle fa-stack-2x"></i>
      <i class="fab fa-github-alt fa-stack-1x fa-inverse"></i>
    </span>
  </a>
  
  
  <a target="_blank" href="https://www.linkedin.com/in/xiaohan-zou-55bba0160">
    <span class="fa-stack fa-lg">
      <i class="fas fa-circle fa-stack-2x"></i>
      <i class="fab fa-linkedin-in fa-stack-1x fa-inverse"></i>
    </span>
  </a>
  
  
  <a target="_blank" href="https://www.facebook.com/renovamen.zou">
    <span class="fa-stack fa-lg">
      <i class="fas fa-circle fa-stack-2x"></i>
      <i class="fab fa-facebook-f fa-stack-1x fa-inverse"></i>
    </span>
  </a>
  
  
  <a target="_blank" href="https://twitter.com/renovamen_zxh">
    <span class="fa-stack fa-lg">
      <i class="fas fa-circle fa-stack-2x"></i>
      <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
    </span>
  </a>
  
  
  <a target="_blank" href="https://www.zhihu.com/people/chao-neng-gui-su">
    <span class="fa-stack fa-lg">
      <i class="fas fa-circle fa-stack-2x"></i>
      <i class="fas fa-stack-1x fa-inverse">知</i>
    </span>
  </a>
  
  
  
  <a href="mailto:renovamenzxh@gmail.com">
    <span class="fa-stack fa-lg">
      <i class="fas fa-circle fa-stack-2x"></i>
      <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
    </span>
  </a>
  
  
  <a target="_blank" href="/feed.xml">
    <span class="fa-stack fa-lg">
      <i class="fas fa-circle fa-stack-2x"></i>
      <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
    </span>
  </a>
  
</div>
    <ul>
        
        <li>
            
            <a href="/" class="faa-parent animated-hover">
            
                
                <i class="fab fa-fort-awesome fa-lg faa-wrench"></i>
                
                Home
            </a>
            
        </li>
        
        <li>
            
            <a href="/about/" class="faa-parent animated-hover">
            
                
                <i class="fas fa-paw fa-lg faa-wrench"></i>
                
                About
            </a>
            
        </li>
        
        <li>
            
            <a href="/archive/" class="faa-parent animated-hover">
            
                
                <i class="fas fa-archive fa-lg faa-wrench"></i>
                
                Archive
            </a>
            
        </li>
        
        <li>
            
            <a href="/links/" class="faa-parent animated-hover">
            
                
                <i class="fas fa-link fa-lg faa-wrench"></i>
                
                Links
            </a>
            
        </li>
        

        <li>
            <a id="mobile-search-btn" class="faa-parent animated-hover">
                <i class="fas fa-search fa-lg faa-wrench"></i> Search
            </a>
        </li>
    </ul>
</div>

    <!-- support search -->
    <div id="search" class="search-page">

    <i class="search-close fas fa-chevron-down"></i>
    <p class="search-title text-center"></p>

    <div class="input">
        <input 
            id="search-input" 
            type="text" 
            class="search-field" 
            placeholder="Just search ..." 
            onkeypress="checkCode()"
            style="background-color: transparent"
        >
    </div>
    <div id="search-results" class="search-results"></div>

    <img class="search-img-right" src="/img/search-right.gif"/>
</div><script>
    // simple-jekyll-search.js
    LazyLoad.js("https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js", function(){
        SimpleJekyllSearch({
            searchInput: document.getElementById('search-input'),
            resultsContainer: document.getElementById('search-results'),
            json: '/search.json',
            searchResultTemplate: '<li class="result-item item"><a href="{url}" title="{desc}"><div class="result-item-title">{title}</div><div class="result-item-subtitle">{subtitle}</div></a></li>',
            noResultsText: '<li class="result-item item"><div class="result-item-title">No Results</div></li>',
            limit: 20,
            fuzzy: false
        })
    })

    // search-results 高度适配
    $('.search-results').css({
        'height': $(window).height() - 200 + "px"
    });

    function checkCode() {
        if (event.keyCode == 13) {
            getCode = $('#search-input').val();
            if(getCode == "cd dark universe") {
                window.location.href = "https://renovamen.gitee.io/dark-universe/";
            }
            else if(getCode == "cd resume") {
                window.location.href = "https://renovamen.ink/Endless-Resume/";
            }
        }
    }

    function autoFocus() {
        setTimeout(function () {
            document.querySelector('.search-page input').focus();
        }, 400);
    }

    // open search page
    $('#search-btn').click(function() {
        $('.search-page').toggleClass('open')
        autoFocus()
    });

    // open search page (mobile)
    $('#mobile-search-btn').click(function() {
        $('.search-page').toggleClass('open')
        autoFocus()
    });

    // close search page
    $('.search-close').click(function() {
        $('.search-page').toggleClass('open')
    });
</script>
    
<!-- Migrate from head to bottom, no longer block render and still work -->

</body>

</html>
