---
layout: post
title: "NLP 不入门直接放弃"
subtitle: "How to give up NLP"
author: "Renovamen"
header-style: text
header-img: img/in-post/2018-02-17/header.jpg
catalog: true
tags:
  - NLP
---

来源：[Melanie Tosik（Twitter:@meltomene）列出的 NLP 学习资源清单](https://towardsdatascience.com/how-to-get-started-in-nlp-6a62aa4eaeff){:target="_blank"}

## Online courses

- [Dan Jurafsky & Chris Manning: Natural Language Processing](https://www.youtube.com/playlist?list=PL8FFE3F391203C98C){:target="_blank"}

- [Stanford CS224d: Deep Learning for Natural Language Processing](http://cs224d.stanford.edu/syllabus.html){:target="_blank"} [更高级的机器学习算法、深度学习和 NLP 的神经网络架构]

- [Coursera: Introduction to Natural Language Processing](https://www.youtube.com/playlist?list=PLLssT5z_DsK8BdawOVCCaTCO99Ya58ryR){:target="_blank"} [密西根大学的 NLP 课程]

## Libraries and open source

- **spaCy** ([website](https://spacy.io){:target="_blank"}, [blog](https://explosion.ai/blog/){:target="_blank"})	[Python；新兴的开放源码库并自带[炫酷的用法示例](https://spacy.io/usage/spacy-101){:target="_blank"}、API 文档和[演示应用程序](https://spacy.io/docs/usage/showcase){:target="_blank"}]

- **Natural Language Toolkit (NLTK)** ([website](http://www.nltk.org/){:target="_blank"}, [book](http://www.nltk.org/book/){:target="_blank"})	[Python；NLP 实用编程介绍，主要用于教学目的]

- **Stanford CoreNLP** ([website](https://stanfordnlp.github.io/CoreNLP/){:target="_blank"})	[由 Java 开发的高质量的自然语言分析工具包]

- **AllenNLP** ([website](https://allennlp.org/){:target="_blank"})	[Python；基于 PyTorch 的 NLP 研究库]

- **fastText** ([website](https://fasttext.cc/){:target="_blank"})	[C++；高效的文本分类（text classification）和表示学习（representation learning）工具]

## Active blogs

- [language processing blog](https://nlpers.blogspot.com/natural){:target="_blank"}	（Hal Daumé III）

- [Language Log](http://languagelog.ldc.upenn.edu/nll/){:target="_blank"}	（Mark Liberman）

- [Google Research blog](https://research.googleblog.com/){:target="_blank"}

- [Explosion AI blog](https://explosion.ai/blog/){:target="_blank"}

- [Hugging Face](https://medium.com/huggingface){:target="_blank"}

- [Sebastian Ruder’s blog](http://ruder.io/#open){:target="_blank"}

## Books

- [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/){:target="_blank"}	（Jurafsky and Martin）[经典的 NLP 教科书，涵盖了所有 NLP 的基础知识，第 3 版即将出版]

- [Foundations of Statistical Natural Language Processing](https://nlp.stanford.edu/fsnlp/){:target="_blank"}	（Manning and Schütze）[更高级的统计 NLP 方法]

- [Introduction to Information Retrieval](https://nlp.stanford.edu/IR-book/){:target="_blank"}	（Manning, Raghavan and Schütze）[关于排名/搜索的优秀参考书]

- [Neural Network Methods in Natural Language Processing](https://www.morganclaypool.com/doi/abs/10.2200/S00762ED1V01Y201703HLT037){:target="_blank"}	（Goldberg）[深入介绍 NLP 的 NN 方法，和相对应的入门书籍]

- [Linguistic Fundamentals for Natural Language Processing](http://www.morganclaypool.com/doi/abs/10.2200/S00493ED1V01Y201303HLT020){:target="_blank"}	（Bender）[更成功的 NLP 的词法和句法]

- [Deep Learning](http://www.deeplearningbook.org/){:target="_blank"}	（Goodfellow, Courville and Bengio）[很好的深度学习介绍]

## Miscellaneous

- [How to build a word2vec model in TensorFlow](https://www.tensorflow.org/versions/master/tutorials/word2vec/index.html){:target="_blank"}	[学习指南]

- [Deep Learning for NLP resources](https://github.com/andrewt3000/dl4nlp){:target="_blank"}	[按主题分类的关于深度学习的顶尖资源的概述]

- [Last Words: Computational Linguistics and Deep Learning — A look at the importance of Natural Language Processing.](http://mitp.nautil.us/article/170/last-words-computational-linguistics-and-deep-learning){:target="_blank"}	（Manning）[文章]

- [Natural Language Understanding with Distributed Representation](https://github.com/nyu-dl/NLP_DL_Lecture_Note/blob/master/lecture_note.pdf){:target="_blank"}	（Cho）[关于 NLU 的 ML / NN 方法的独立讲义]

- [Bayesian Inference with Tears](http://www.isi.edu/natural-language/people/bayes-with-tears.pdf){:target="_blank"}	（Knight）[教程工作簿]

- [Association for Computational Linguistics](http://aclanthology.info/){:target="_blank"} （ACL）[期刊选集]

- [Quora: How do I learn Natural Language Processing?](https://www.quora.com/How-do-I-learn-Natural-Language-Processing){:target="_blank"}

- [Natural Language Understanding and Computational Semantics](https://docs.google.com/document/d/1mkB6KA7KuzNeoc9jW3mfOthv_6Uberxs8l2H7BmJdzg/edit){:target="_blank"}	（Bowman）[开源的课程大纲和完整幻灯片]

- [fast.ai](http://www.fast.ai/){:target="_blank"}	[“Making neural nets uncool again”]

## DIY projects and data sets

Nicolas Iderhoff 已经创建了一份[公开、详尽的 NLP 数据集的列表](https://github.com/niderhoff/nlp-datasets){:target="_blank"}。除了这些，这里还有一些推荐的项目：

- Implement a [part-of-speech (POS) tagger (词性标注)](https://en.wikipedia.org/wiki/Part-of-speech_tagging){:target="_blank"} based on a [hidden Markov model (HMM) (隐马尔可夫模型)](https://en.wikipedia.org/wiki/Hidden_Markov_model){:target="_blank"}

- Implement the [CYK algorithm](https://en.wikipedia.org/wiki/CYK_algorithm){:target="_blank"} for parsing [context-free grammars](https://en.wikipedia.org/wiki/Context-free_grammar){:target="_blank"}

- Implement [semantic similarity (语义相似度)](https://en.wikipedia.org/wiki/Semantic_similarity){:target="_blank"} between two given words in a collection of text, e.g. [pointwise mutual information (PMI) (点互信息)](https://en.wikipedia.org/wiki/Pointwise_mutual_information){:target="_blank"}

- Implement a [Naive Bayes classifier (朴素贝叶斯分类器)](https://en.wikipedia.org/wiki/Naive_Bayes_classifier){:target="_blank"} to [filter spam](https://en.wikipedia.org/wiki/Naive_Bayes_spam_filtering){:target="_blank"}

- Implement a [spell checker](https://en.wikipedia.org/wiki/Spell_checker){:target="_blank"} based on [edit distances](https://en.wikipedia.org/wiki/Edit_distance){:target="_blank"} between words

- Implement a [Markov chain (马尔科夫链)](https://en.wikipedia.org/wiki/Markov_chain){:target="_blank"} text generator

- Implement a [topic model](https://en.wikipedia.org/wiki/Topic_model){:target="_blank"} using [latent Dirichlet allocation (LDA)](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation){:target="_blank"}

- Use [word2vec](https://code.google.com/archive/p/word2vec/){:target="_blank"} to generate word embeddings from a large text corpus, e.g. [Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:Database_download){:target="_blank"}

- Use [k-means](https://en.wikipedia.org/wiki/K-means_clustering){:target="_blank"} to cluster [tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf){:target="_blank"} vectors of text, e.g. news articles

- Implement a [named-entity recognizer (NER) (命名实体识别)](https://en.wikipedia.org/wiki/Named-entity_recognition){:target="_blank"} (also called a name tagger), e.g. following the [CoNLL-2003 shared task](https://www.clips.uantwerpen.be/conll2003/ner/){:target="_blank"}

## NLP on social media

- Twitter: [#nlproc](https://twitter.com/hashtag/nlproc){:target="_blank"}, [list of NLPers](https://twitter.com/hashtag/nlproc){:target="_blank"} (by Jason Baldrige)

- Reddit: [/r/LanguageTechnology](https://www.reddit.com/r/LanguageTechnology){:target="_blank"}

- Medium: [NLP](https://medium.com/tag/nlp){:target="_blank"}