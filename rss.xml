<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Xiaohan Zou]]></title><description><![CDATA[Xiaohan Zou (Renovamen) is a dragon lost in human world.]]></description><link>https://zxh.io</link><generator>RSS for Node</generator><lastBuildDate>Wed, 13 Apr 2022 03:07:17 GMT</lastBuildDate><atom:link href="https://zxh.io/rss.xml" rel="self" type="application/rss+xml"/><copyright><![CDATA[Renovamen 2018-2022]]></copyright><language><![CDATA[en]]></language><item><title><![CDATA[同余运算]]></title><description><![CDATA[<p>在 CS 538 密码学彻底躺平之后的一次记录。</p>
]]></description><link>https://zxh.io/post/2022/03/21/modular-arithmetic/</link><guid isPermaLink="true">https://zxh.io/post/2022/03/21/modular-arithmetic/</guid><dc:creator><![CDATA[Renovamen]]></dc:creator><pubDate>Mon, 21 Mar 2022 00:00:00 GMT</pubDate></item><item><title><![CDATA[2022 新年快乐]]></title><description><![CDATA[<p>不管是按公历新年，还是按中国新年，在这个点说新年快乐都显得格格不入，<s>但反正也没人看也就无所谓了</s>。</p>
]]></description><link>https://zxh.io/post/2022/02/21/new-year-2022/</link><guid isPermaLink="true">https://zxh.io/post/2022/02/21/new-year-2022/</guid><dc:creator><![CDATA[Renovamen]]></dc:creator><pubDate>Mon, 21 Feb 2022 00:00:00 GMT</pubDate></item><item><title><![CDATA[波士顿漫游指南]]></title><description><![CDATA[<p>在 gap 了一年，又上了一学期网课以后，我终于来了波士顿。</p>
]]></description><link>https://zxh.io/post/2022/01/29/travel-to-boston/</link><guid isPermaLink="true">https://zxh.io/post/2022/01/29/travel-to-boston/</guid><dc:creator><![CDATA[Renovamen]]></dc:creator><pubDate>Sat, 29 Jan 2022 00:00:00 GMT</pubDate></item><item><title><![CDATA[Attention / Conv 大锅烩]]></title><description><![CDATA[<p>长期记录和实现看过的各种论文里的自注意力和卷积机制，咕咕咕，实现地址在：<a href="https://github.com/Renovamen/torchop" target="_blank" rel="noopener noreferrer"><v-icon name="ri-link-m" scale="0.9"/> Github</a></p>
]]></description><link>https://zxh.io/post/2021/08/31/attention-conv/</link><guid isPermaLink="true">https://zxh.io/post/2021/08/31/attention-conv/</guid><dc:creator><![CDATA[Renovamen]]></dc:creator><pubDate>Tue, 31 Aug 2021 00:00:00 GMT</pubDate></item><item><title><![CDATA[自然梯度下降]]></title><description><![CDATA[<p>自然梯度下降（Natural Gradient Decent）把参数看成一种概率分布，然后使用 KL 散度而不是欧氏距离来作为距离的度量，从而更好地描述更新后的分布和原分布有多大的不同。</p>
]]></description><link>https://zxh.io/post/2021/07/28/natural-gradient/</link><guid isPermaLink="true">https://zxh.io/post/2021/07/28/natural-gradient/</guid><dc:creator><![CDATA[Renovamen]]></dc:creator><pubDate>Wed, 28 Jul 2021 00:00:00 GMT</pubDate></item><item><title><![CDATA[Fisher 信息矩阵]]></title><description><![CDATA[<p>Fisher 信息矩阵的数学意义和直观上的理解。</p>
]]></description><link>https://zxh.io/post/2021/07/27/fisher-information-matrix/</link><guid isPermaLink="true">https://zxh.io/post/2021/07/27/fisher-information-matrix/</guid><dc:creator><![CDATA[Renovamen]]></dc:creator><pubDate>Tue, 27 Jul 2021 00:00:00 GMT</pubDate></item><item><title><![CDATA[支持向量机]]></title><description><![CDATA[<p>SVM（Support Vector Machine，支持向量机）是一种二类分类模型，目标是在特征空间上找到间隔最大化的超平面。</p>
]]></description><link>https://zxh.io/post/2021/06/12/svm/</link><guid isPermaLink="true">https://zxh.io/post/2021/06/12/svm/</guid><dc:creator><![CDATA[Renovamen]]></dc:creator><pubDate>Sat, 12 Jun 2021 00:00:00 GMT</pubDate></item><item><title><![CDATA[PC 算法]]></title><description><![CDATA[<p>把大三的时候在实验室摸鱼看贝叶斯网络和 PC 算法时写的笔记整理到这里来，免得哪天我换电脑时把笔记搞没了。</p>
]]></description><link>https://zxh.io/post/2021/04/26/pc-algorithm/</link><guid isPermaLink="true">https://zxh.io/post/2021/04/26/pc-algorithm/</guid><dc:creator><![CDATA[Renovamen]]></dc:creator><pubDate>Mon, 26 Apr 2021 00:00:00 GMT</pubDate></item><item><title><![CDATA[凌乱的 PyTorch 笔记]]></title><description><![CDATA[<p>记录一些 PyTorch 的细节。</p>
]]></description><link>https://zxh.io/post/2021/01/28/lets-talk-about-pytorch/</link><guid isPermaLink="true">https://zxh.io/post/2021/01/28/lets-talk-about-pytorch/</guid><dc:creator><![CDATA[Renovamen]]></dc:creator><pubDate>Thu, 28 Jan 2021 00:00:00 GMT</pubDate></item><item><title><![CDATA[新年快乐]]></title><description><![CDATA[<p>太长不看版：顺位第一的新年愿望是能成为一个温暖的人类，如果这个愿望今年无法实现，那就先当一个正常一些的人类吧。</p>
]]></description><link>https://zxh.io/post/2021/01/01/new-year/</link><guid isPermaLink="true">https://zxh.io/post/2021/01/01/new-year/</guid><dc:creator><![CDATA[Renovamen]]></dc:creator><pubDate>Fri, 01 Jan 2021 00:00:00 GMT</pubDate></item><item><title><![CDATA[关于博客的碎碎念]]></title><description><![CDATA[<p>“虽然研究进度堪忧，但鱼还是要摸的”，在这样的理念的驱动下，菜鸡最终折腾出了一个目前看上去还算可以的方案。</p>
]]></description><link>https://zxh.io/post/2020/10/07/my-blog/</link><guid isPermaLink="true">https://zxh.io/post/2020/10/07/my-blog/</guid><dc:creator><![CDATA[Renovamen]]></dc:creator><pubDate>Wed, 07 Oct 2020 00:00:00 GMT</pubDate></item><item><title><![CDATA[Bayesian MAML]]></title><description><![CDATA[<p>为了引入不确定性<s>和多找一个发论文的话题</s>，MAML 还可以用贝叶斯视角来理解。</p>
]]></description><link>https://zxh.io/post/2020/09/04/bayesian-meta-learning/</link><guid isPermaLink="true">https://zxh.io/post/2020/09/04/bayesian-meta-learning/</guid><dc:creator><![CDATA[Renovamen]]></dc:creator><pubDate>Fri, 04 Sep 2020 00:00:00 GMT</pubDate></item><item><title><![CDATA[Regularization-based Continual Learning]]></title><description><![CDATA[<p>基于正则（regularization-based）的持续学习：用一个表示参数重要程度的正则项来控制参数在未来的任务中的更新幅度。</p>
]]></description><link>https://zxh.io/post/2020/08/24/regularization-based-continual-learning/</link><guid isPermaLink="true">https://zxh.io/post/2020/08/24/regularization-based-continual-learning/</guid><dc:creator><![CDATA[Renovamen]]></dc:creator><pubDate>Mon, 24 Aug 2020 00:00:00 GMT</pubDate></item><item><title><![CDATA[BOCD]]></title><description><![CDATA[<p>给定一个数据序列，在某个时间点，数据的某个（或某些）参数可能由于系统性因素（而非偶然性因素）而突然发生变化，那么这个时间点被称为<strong>变点</strong>（changepoint）。</p>
]]></description><link>https://zxh.io/post/2020/08/22/bocd/</link><guid isPermaLink="true">https://zxh.io/post/2020/08/22/bocd/</guid><dc:creator><![CDATA[Renovamen]]></dc:creator><pubDate>Sat, 22 Aug 2020 00:00:00 GMT</pubDate></item><item><title><![CDATA[贝叶斯神经网络]]></title><description><![CDATA[<p>Radford Neal: I don't necessarily think that the Bayesian method is the best thing to do in all cases...</p>
]]></description><link>https://zxh.io/post/2020/08/16/bayesian-neural-network/</link><guid isPermaLink="true">https://zxh.io/post/2020/08/16/bayesian-neural-network/</guid><dc:creator><![CDATA[Renovamen]]></dc:creator><pubDate>Sun, 16 Aug 2020 00:00:00 GMT</pubDate></item><item><title><![CDATA[元学习：一种套娃算法]]></title><description><![CDATA[<p>continual learning 方向 19 年之后的<a href="https://note.zxh.io/papers/dl/continual-learning.html#meta-learning" target="_blank" rel="noopener noreferrer">几篇论文</a>搞出了一个套 meta learning 框架（主要是 MAML 这种 optimization-based 的方法）的新思路。</p>
]]></description><link>https://zxh.io/post/2020/08/05/meta-learning/</link><guid isPermaLink="true">https://zxh.io/post/2020/08/05/meta-learning/</guid><dc:creator><![CDATA[Renovamen]]></dc:creator><pubDate>Wed, 05 Aug 2020 00:00:00 GMT</pubDate></item><item><title><![CDATA[Transformer]]></title><description><![CDATA[<p><strong>Attention Is All You Need.</strong> <em>Ashish Vaswani, et al.</em> NIPS 2017. <a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf" target="_blank" rel="noopener noreferrer">[Paper]</a> <a href="https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py" target="_blank" rel="noopener noreferrer">[Code]</a></p>
]]></description><link>https://zxh.io/post/2020/07/17/transformer/</link><guid isPermaLink="true">https://zxh.io/post/2020/07/17/transformer/</guid><dc:creator><![CDATA[Renovamen]]></dc:creator><pubDate>Fri, 17 Jul 2020 00:00:00 GMT</pubDate></item><item><title><![CDATA[乱七八糟的知识点]]></title><description><![CDATA[<p>菜鸡在失学失业的惊慌失措之下的胡乱总结，又因为懒惰压制了惊慌失措所以并没有总结多少...</p>
]]></description><link>https://zxh.io/post/2020/07/10/messy-notes-nlp/</link><guid isPermaLink="true">https://zxh.io/post/2020/07/10/messy-notes-nlp/</guid><dc:creator><![CDATA[Renovamen]]></dc:creator><pubDate>Fri, 10 Jul 2020 00:00:00 GMT</pubDate></item><item><title><![CDATA[三月大锅烩]]></title><description><![CDATA[<p>看过的关于机器翻译 / 文本摘要 / 图像描述的论文的总结，到时候大概也可以直接复制粘贴进毕业论文里。</p>
]]></description><link>https://zxh.io/post/2020/03/17/papers-reading/</link><guid isPermaLink="true">https://zxh.io/post/2020/03/17/papers-reading/</guid><dc:creator><![CDATA[Renovamen]]></dc:creator><pubDate>Tue, 17 Mar 2020 00:00:00 GMT</pubDate></item><item><title><![CDATA[图像美感评估]]></title><description><![CDATA[<p>对图像美感评估（Image Aesthetic Assessment）领域的简单调研，到时候大概可以直接复制粘贴进毕业论文里。</p>
]]></description><link>https://zxh.io/post/2020/02/29/image-aesthetic-assessment/</link><guid isPermaLink="true">https://zxh.io/post/2020/02/29/image-aesthetic-assessment/</guid><dc:creator><![CDATA[Renovamen]]></dc:creator><pubDate>Sat, 29 Feb 2020 00:00:00 GMT</pubDate></item></channel></rss>